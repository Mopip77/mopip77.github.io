[ { "title": "zerotier配置", "url": "/posts/zerotier%E9%85%8D%E7%BD%AE/", "categories": "", "tags": "nas, zerotier", "date": "2022-11-10 00:00:00 +0800", "snippet": "本文主要介绍如何使用zerotier进行虚拟局域网的搭建。内容包含zerotier下载安装,moon节点搭建,router配置。zerotier下载安装zerotier的官方下载地址: https://www.zerotier.com/download/大部分操作平台可以在这直接下载，对于以下部分平台有代替软件或者需要额外配置android建议使用ZerotierFix代替，此软件支持配置Moon节点qnap在升级到qnap 5.0.1之后zerotier 1.10.1会启动报错，需要按照以下方式配置，如果后续qnap或者zerotier升级修复，则无需关注https://forum.qnap.com/viewtopic.php?t=167752Moon节点搭建网上教程较多，不赘述，需要一台公网服务器，随意找一个教程搭建即可https://www.cnblogs.com/Yogile/p/12642423.htmlrouter配置假设你家有一台路由器(lan-ip: 192.168.2.1)，一台nas(lan-ip:192.168.2.2)此时你希望手机能直接连接到家里的nas，那么需要将nas和手机同时加入到zerotier的虚拟局域网中nas(lan-ip:192.168.2.2, zt-ip:192.168.192.2), phone(zt-ip:192.168.192.100)均加入zerotier之后，手机可以通过zt-ip来访问nas这样虽然能访问，但是有两个缺点： 如果家里局域网有多个设备需要加入到zerotier，那每个设备都需要安装/配置zerotier，非常繁琐，甚至有的设备不能安装zerotier 手机连接局域网设备需要两套配置，在局域网内配置一套lan-ip，在外面的zt网络配置配置zt-ip，每次需要切换，不能无感切换设想一下，假如我们把一台局域网的设备加入zerotier网络，并将该设备作为路由(router)，所有访问局域网内其他设备的流量均由这台路由代理，那么局域网内设备就无需加入zerotier网络。并且可以设置成手机访问局域网网段(192.168.2.x)也由这台路由代理，这样手机不论在局域网内，还是在外面的zt网络内，都可以通过nas的lan-ip来访问naslinux配置以支持iptables的linux设备为例，可以是你家的路由器、nas或树莓派。这台路由的ip假定为(lan-ip:192.168.2.1, zt-ip:192.168.192.3)zerotier网络配置路由转发将局域网的网段(192.168.2.0/24)全部由zerotier的ip转发配置路由网络转发官方教程: 链接🔗ssh进入到路由设备的后台 打开ipv4的路由转发 sudo sysctl -w net.ipv4.ip_forward=1 配置路由表 # PHY_IFACE为物理网卡地址 PHY_IFACE=eth0 # ZT_IFACE为zerotier虚拟网卡地址 ZT_IFACE=zt7nnig26 # 这两个网卡地址可以通过 ip a 查看 # 配置iptables转发规则 sudo iptables -t nat -A POSTROUTING -o $PHY_IFACE -j MASQUERADE sudo iptables -A FORWARD -i $PHY_IFACE -o $ZT_IFACE -m state --state RELATED,ESTABLISHED -j ACCEPT sudo iptables -A FORWARD -i $ZT_IFACE -o $PHY_IFACE -j ACCEPT # 配置持久性，下次重启也生效（如果不支持该命令，自行查找解决） sudo apt install iptables-persistent sudo bash -c iptables-save &amp;gt; /etc/iptables/rules.v4 Done 此时应该已经生效了，试试用你的zerotier设备通过局域网ip访问家里的设备吧。 补充配置 你应该可以通过lan-ip访问所有其他局域网设备，但唯独不能通过路由的lan-ip(192.168.2.1)访问路由。如果你没有这个需求你可以搁置不处理，但我这用的是nas作为路由，如果不能通过nas的lan-ip来访问nas，那么仍然没有解决上述的问题。 原理不解释了，直接说结论。我们需要配置一下路由设备自身ip访问的DNAT iptables -t nat -I PREROUTING -i &amp;lt;zt-nic&amp;gt; -d &amp;lt;ROUTER-LAN-IP&amp;gt; -j DNAT --to-destination &amp;lt;ROUTER-ZT-IP&amp;gt; # 以上面这个例子，配置如下 iptables -t nat -I PREROUTING -i $ZT_IFACE -d 192.168.2.1 -j DNAT --to-destination 192.168.192.3 执行后，应该就能通过路由的lan-ip(192.168.2.1)直接访问路由设备了。 Mac作为路由配置假如你使用Mac作为路由，由于其不支持iptables，而是使用的pfctl，因此配置上稍有不同 打开ipv4的路由转发 sysctl -w net.inet.ip.forwarding=1 配置pf 新增/etc/pf.zerotier.conf，增加以下配置 # PHY_IFACE为物理网卡地址 PHY_IFACE=en0 # ZT_IFACE为zerotier虚拟网卡地址 ZT_IFACE=zt7nnig26 # 这两个网卡地址可以通过 ip a 查看 nat on $PHY_IFACE from $ZT_IFACE:network to any -&amp;gt; ($PHY_IFACE) 更新pf配置 执行sudo pfctl -e -f /etc/pf.zerotier.conf " }, { "title": "qnap备忘录", "url": "/posts/qnap%E5%A4%87%E5%BF%98%E5%BD%95/", "categories": "", "tags": "nas", "date": "2022-10-11 00:00:00 +0800", "snippet": "一些容易忘记但是常用的东西命令行安装.qpkg安装包# 安装并移除安装包qpkg_cli -m xxx.qpkgcrontabqnap的crontab在重启后会丢失，因此不能使用常规的crontab -e来编写# 编辑cronvim /etc/config/crontab# cron生效crontab /etc/config/crontab# 重启cron/etc/init.d/crond.sh restartrsync备份涉及两个硬盘池之间的冷备，防止单硬盘池损坏导致重要数据丢失的问题# cron表达式12 3 * * * /usr/bin/rsync -avv --exclude=&#39;.*&#39; --exclude=&#39;@*&#39; /share/photo/ /share/backup/photo_backup/ &amp;gt;&amp;gt; /share/backup/photo_backup/backup.logrclone备份nas文件备份到网盘，防止整个nas损坏而导致的文件丢失# cron表达式4 4 * * * /usr/bin/rclone sync --exclude &#39;.@__thumb/**&#39; --delete-excluded --log-file /share/grampro/rclone/photo-backup-$(date +%F).log -v /share/photo one:/photo" }, { "title": "maven技巧", "url": "/posts/maven%E6%8A%80%E5%B7%A7/", "categories": "", "tags": "maven", "date": "2022-05-31 00:00:00 +0800", "snippet": "展示一些maven的使用技巧依赖相关展示项目所有依赖mvn help:effective-pom -Dverbose该命令会将项目的所有依赖pom文件整合成一个，并且使用了-Dverbose参数，会将每个dependency或者dependencyManagement的原引用给打印出来。举个栗子# property&amp;lt;rsocket.version&amp;gt;1.1.1&amp;lt;/rsocket.version&amp;gt; &amp;lt;!-- org.springframework.boot:spring-boot-dependencies:2.5.4, line 185 --&amp;gt;# dependency&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.grpc&amp;lt;/groupId&amp;gt; &amp;lt;!-- com.example:bailing-test:0.0.1-SNAPSHOT, line 23 --&amp;gt; &amp;lt;artifactId&amp;gt;grpc-netty-shaded&amp;lt;/artifactId&amp;gt; &amp;lt;!-- com.example:bailing-test:0.0.1-SNAPSHOT, line 24 --&amp;gt; &amp;lt;version&amp;gt;1.31.1&amp;lt;/version&amp;gt; &amp;lt;!-- com.example:bailing-test:0.0.1-SNAPSHOT, line 25 --&amp;gt;&amp;lt;/dependency&amp;gt;参数相关指定settingsmvn -s settings.xmlmvnd使用mvnd代替mvn，mvnd会在后台启动maven的daemon服务，省去了每次启动mvn服务的时间；多线程流水线编译，提高编译速度。" }, { "title": "PT plugin plus chrome安装", "url": "/posts/pt-plugins-chrome%E5%AE%89%E8%A3%85/", "categories": "", "tags": "mac", "date": "2021-11-18 00:00:00 +0800", "snippet": "pt plugin 由于被Chrome移除了，无法通过chrome商店下载，因此记录一下安装方式通过常规的zip或crx安装会在chrome重启之后，被chrome自动移除下面的两种安装方式通过设置Chrome Extension白名单实现永久安装Windowswindows的安装比较简单，官方也给出了安装手册，windows 通过crx安装MACmac需要写入一个配置文件，起名为com.google.Chrome.mobileconfig&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&amp;lt;!DOCTYPE plist PUBLIC &quot;-//Apple//DTD PLIST 1.0//EN&quot; &quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&amp;gt;&amp;lt;plist version=&quot;1.0&quot;&amp;gt;&amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;PayloadContent&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;PayloadContent&amp;lt;/key&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;com.google.Chrome&amp;lt;/key&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;Forced&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;mcx_preference_settings&amp;lt;/key&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;ExtensionInstallWhitelist&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;string&amp;gt;dmmjlmbkigbgpnjfiimhlnbnmppjhpea&amp;lt;/string&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;/dict&amp;gt; &amp;lt;/dict&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;/dict&amp;gt; &amp;lt;/dict&amp;gt; &amp;lt;key&amp;gt;PayloadEnabled&amp;lt;/key&amp;gt; &amp;lt;true/&amp;gt; &amp;lt;key&amp;gt;PayloadIdentifier&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;MCXToProfile.7e2bec75-299e-44ff-b405-628007abffff.alacarte.customsettings.bdac4880-d25f-4cdd-8472-05473f005e7e&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;PayloadType&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;com.apple.ManagedClient.preferences&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;PayloadUUID&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;bdac4880-d25f-4cdd-8472-05473f005e7e&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;PayloadVersion&amp;lt;/key&amp;gt; &amp;lt;integer&amp;gt;1&amp;lt;/integer&amp;gt; &amp;lt;/dict&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;key&amp;gt;PayloadDescription&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;Included custom settings:com.google.Chrome&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;PayloadDisplayName&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;MCXToProfile: com.google.Chrome&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;PayloadIdentifier&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;com.google.Chrome&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;PayloadOrganization&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;PayloadRemovalDisallowed&amp;lt;/key&amp;gt; &amp;lt;true/&amp;gt; &amp;lt;key&amp;gt;PayloadScope&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;System&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;PayloadType&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;Configuration&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;PayloadUUID&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;7e2bec75-299e-44ff-b405-628007abffff&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;PayloadVersion&amp;lt;/key&amp;gt; &amp;lt;integer&amp;gt;1&amp;lt;/integer&amp;gt;&amp;lt;/dict&amp;gt;&amp;lt;/plist&amp;gt;写入之后，双击该文件安装即可然后通过crx安装插件" }, { "title": "netcat使用", "url": "/posts/netcat%E4%BD%BF%E7%94%A8/", "categories": "", "tags": "linux, netcat", "date": "2021-02-07 00:00:00 +0800", "snippet": "传递文件单个文件nc -l -p 1234 &amp;gt; out.filewill begin listening on port 1234.nc -w 3 [destination] 1234 &amp;lt; out.filewill connect to the receiver and begin sending file.多个文件On the receiving end,nc -l -p 1234 | uncompress -c | tar xvfp -On the sending end,tar cfp - /some/dir | compress -c | nc -w 3 [destination] 1234python方法除了使用nc进行文件传输外，还可以使用python自带的http file server模块，无需下载ncpython2python -m SimpleHTTPServer &amp;lt;port&amp;gt;python3python3 -m http.server &amp;lt;port&amp;gt;这两个都是相对路径的文件共享,直接使用curl命令下载即可,例如共享文件夹内有a.txtcurl -O http://&amp;lt;ip&amp;gt;:&amp;lt;port&amp;gt;/a.txt" }, { "title": "Nas通过Frp暴露到外网", "url": "/posts/Nas%E9%80%9A%E8%BF%87Frp%E6%9A%B4%E9%9C%B2%E5%88%B0%E5%A4%96%E7%BD%91/", "categories": "", "tags": "nas, frp", "date": "2020-11-06 00:00:00 +0800", "snippet": "本文主要通过frp（一种内网穿透的工具）将nas中的samba端口暴露到外网上，方便在外面也能访问到家里nas的数据。项目启动缘由说来也巧，我airpods pro耳机到的那天，正好是我QQ音乐会员到期的那天。所以，我在试耳机的时候，发现QQ音乐总会无端的自动切歌，我一度怀疑是我耳机的问题，马上都准备要退货了，百度一下才发现居然是QQ音乐普通用0户听会员歌曲只能听1分钟，到时间QQ音乐就自动切歌。这一下，我属实被恶心到了。当然我是对他们维护音乐版权不排斥的，但是，我觉得直接不让我们听都比现在的方式要合理，这样纯粹有点恶心人了。有点扯远了，总而言之，恰巧我有一些音频的获取方式，也在家里的nas中下载了一些音频，当时我就想为何我不直接通过把家里nas的内容共享到外网上，即免费又有高音质。项目选型现在公网IP越来越难获取，何况我还是蹭的室友的网，更不可能获取到公网IP了，索性只能通过内网穿透的方式把家里的nas服务暴露出去了。准备工作要达到这一目标，我们首先需要你有一些基础的准备。 一个开启了samba的nas 一台VPS（也可以没有）开启samba以及在防火墙开放对应的端口由于每个人的nas设备不一样，我就不介绍samba的开启方法了，主要需要注意两点，由于是暴露在公网上，所以最好把重要的内容用账号隔离开，以及不要给写权限。接着开启对应的端口，由于samba默认的端口445，所以我们开启一下这个端口的tcp和udp使用frp进行端口暴露使用自己的VPS进行流量转发如果你有一台带宽不小的VPS，完全可以使用自己的VPS进行frp的转发，一来比较好修改，二来比较安全。客户端frpc的配置这里的客户端，也就是我们家的nas，需要对frp进行如下配置server_addr指定VPS的ipserver_port指定VPS用于和nas进行通信的端口（需要暴露出来）local_ip指定nas的ip，本来可以指定127.0.0.1，但是不知道为什么我这如果配后者不生效local_port指定nas开启samba服务的端口，也就是默认的445remote_port指定远程连接的端口（需要暴露出来）使用如下命令启动即可服务器端frps的配置服务器端配置非常简单，就是指定用于通信的端口之后直接启动即可使用免费的frp代理平台服务进行转发这也是我才知道的一类平台，由于我的服务器只有1M的垃圾带宽，所以听一些无损音乐都卡的不行，因此才发现了这类的平台: natfrp。免费用户是10M的带宽，当然我测出来是只有3M左右，但是听音乐，甚至看1080P的电影电视剧都是毫无压力的，所以在这里也分享一下这个平台的配置方法。在左边的菜单栏里点击【创建隧道】，并进行如下配置对比上面可以发现，其实就是frpc配置文件的图形化配置，并没有什么额外的高级配置，之后点击【确认创建】就会生成一个新的隧道。点击左侧的【隧道列表】，可以看见我们刚刚创建的隧道，对应到刚刚的vps配置，ip就是他们提供的url，端口是左侧箭头指向的位置。点击【配置文件】，会弹出一个框，这个就是frpc的配置，也就是nas中frp的配置，这个网站已经帮我们生成好了，我们只需要复制到nas中开启frpc即可。外部连接进行到这，samba服务已经暴露出去了，我们现在可以使用支持samba的客户端进行访问了，以mac为例，打开mac的Finder的【连接服务器】，输入对应的域名+端口连接即可。可以访问了！！额外服务我们的音乐已经的暴露出来了，现在在任何场景都能访问了，但是有时候网络不好等等情况，我们的音频太大，例如我现在存储的都是flac，基本上30MB一首歌，所以我希望是把他们压缩以后单独存储一下。转码脚本，这个需要nas上安装ffmpeg#!/bin/bash################################################################# 自动同步转码程序 #### #### 对于高码率的文件（例如flac和wav格式的音频进行转码） #### 并在对应的转码文件夹下创建完全一样的文件夹结构 #### #################################################################ROOT_PATH=&quot;/Users/bjhl/gogo&quot; # 音乐文件夹ENCODE_PATH=&quot;/Users/bjhl/encode&quot; # 转码后的文件夹，可以不存在SUPPORT_TRANSCODE_EXT=(flac wav)COPY_EXT=(jpeg jpg png)checkSupportExt() { local type=&quot;$1&quot; for supportType in ${SUPPORT_TRANSCODE_EXT[@]}; do [ &quot;${supportType}&quot; = &quot;${type}&quot; ] &amp;amp;&amp;amp; exit 0 done exit 1}checkCopyExt() { local type=&quot;$1&quot; for supportType in ${COPY_EXIT[@]}; do [ &quot;${supportType}&quot; = &quot;${type}&quot; ] &amp;amp;&amp;amp; exit 0 done exit 1}encode() { local sourceFile=&quot;$1&quot; local targetFolder=&quot;$2&quot; local fileName=&quot;$3&quot; local targetFile=&quot;${targetFolder}/${fileName}.aac&quot; echo &quot;transcoding from [${sourceFile}] to [${targetFolder}]&quot; ffmpeg -n -v error -i &quot;${sourceFile}&quot; -ar 44100 -ac 2 -ab 320k &quot;${targetFile}&quot;}sync() { # 当前文件夹路径 local folderPath=&quot;$1&quot; local targetPath=&quot;$2&quot; if [ ! -d &quot;${targetPath}&quot; ]; then echo &quot;mkdir: ${targetPath}&quot; mkdir &quot;${targetPath}&quot; fi OLD_IFS=&quot;$IFS&quot; IFS=$&#39;\\n&#39; for f in `ls &quot;${folderPath}&quot;`; do # 当前文件 local file=&quot;${folderPath}/${f}&quot; [ -L &quot;${file}&quot; ] &amp;amp;&amp;amp; continue # 如果是链接文件直接过滤，怕有死循环 [ -d &quot;${file}&quot; ] &amp;amp;&amp;amp; sync &quot;${file}&quot; &quot;${targetPath}/${f}&quot; if [ -f &quot;${file}&quot; ]; then local ext=&quot;${file##*.}&quot; local fn=&quot;${f%.*}&quot; if `checkSupportExt &quot;${ext}&quot;`; then encode &quot;${file}&quot; &quot;${targetPath}&quot; &quot;${fn}&quot; elif `checkCopyExt &quot;${ext}&quot;`; then echo &quot;[copy file] ${file}&quot; cp &quot;${file}&quot; &quot;${targetPath}/${f}&quot; else echo &quot;[ext not support] ${file}&quot; fi fi done IFS=$OLD_IFS}folderPrepare() { if [[ &quot;${ENCODE_PATH}&quot; =~ &quot;${ROOT_PATH}&quot; ]]; then echo &quot;不可以套娃哦！&quot; exit 0 fi if [ ! -d &quot;${ROOT_PATH}&quot; ]; then echo &quot;您的原文件夹呢？&quot; exit 0 fi if [ ! -d &quot;${ENCODE_PATH}&quot; ]; then mkdir -p &quot;${ENCODE_PATH}&quot; fi}main() { folderPrepare &quot;${ROOT_PATH}&quot; &quot;${ENCODE_PATH}&quot; sync &quot;${ROOT_PATH}&quot; &quot;${ENCODE_PATH}&quot;}main需要自己配置的是前两个变量ROOT_PATH 存储音频的原文件夹ENCODE_PATH 转码后的音频的文件夹这个脚本会保证文件夹结构原封不动地复制过去。如果遇到flac、wav文件会转码成aac文件并复制过去。如果遇到图片格式jpg等（可能是cover）会直接复制过去。其他的文件类型直接忽略。" }, { "title": "Guava小笔记", "url": "/posts/guava%E5%B0%8F%E7%AC%94%E8%AE%B0/", "categories": "", "tags": "Guava", "date": "2020-09-03 00:00:00 +0800", "snippet": "null使用Optional的意义在哪儿？使用Optional除了赋予null语义，增加了可读性，最大的优点在于它是一种傻瓜式的防护。Optional迫使你积极思考引用缺失的情况，因为你必须显式地从Optional获取引用。直接使用null很容易让人忘掉某些情形，尽管FindBugs可以帮助查找null相关的问题，但是我们还是认为它并不能准确地定位问题根源。如同输入参数，方法的返回值也可能是null。和其他人一样，你绝对很可能会忘记别人写的方法method(a,b)会返回一个null，就好像当你实现method(a,b)时，也很可能忘记输入参数a可以为null。将方法的返回类型指定为Optional，也可以迫使调用者思考返回的引用缺失的情形。当你需要用一个默认值来替换可能的null，请使用Objects.firstNonNull(T, T) 方法。好的做法是积极地把null和空区分开，以表示不同的含义，在代码中把null和空同等对待是一种令人不安的坏味道。" }, { "title": "Git骚操作", "url": "/posts/Git%E9%AA%9A%E6%93%8D%E4%BD%9C/", "categories": "", "tags": "Git", "date": "2020-08-06 00:00:00 +0800", "snippet": " git强制LF多环境开发的情况下，很有可能UNIX和WIN并行开发，由于UNIX的换行符是LF（0x0A），WIN是CRLF（0x0D0A），因此需要强制指定一致的换行符。# 提交时转换为LF，检出时不转换git config --global core.autocrlf input# 拒绝提交包含混合换行符的文件git config --global core.safecrlf true 更新远端分支列表git remote update origin --prune执行这条命令，你本地的连接的远程分支必须属于origin 查看两个分支的公共父节点git merge-base A B这两个分支必须是本地分支，使用这个能查看出一个commit hash值，再使用git log使用vim的查找方法就能定位commit 当然为了跟方便点，可以只查看hash号的前7位echo ${&quot;$(git merge-base A B)&quot;:0:7}" }, { "title": "一站式下载平台搭建", "url": "/posts/%E4%B8%80%E7%AB%99%E5%BC%8F%E4%B8%8B%E8%BD%BD%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/", "categories": "", "tags": "bt, 下载", "date": "2020-07-31 00:00:00 +0800", "snippet": "本教程适用于没有pt使用经验，但有vps经验的小伙伴使用。随着现在中国的版权意识越来越强，我们在正常的视频平台（腾讯、B站）基本无法看到未购买版权的国外电视剧了，网上随处找的资源又参差不齐，模糊卡顿，所以一般我们使用bt的方式下载高清的番剧，但是下载后的存储和随处访问又成了问题，这里最推荐还是使用本地硬盘存储。所以这里最终的推荐是使用Onedrive来存储，对于会员有1TB的存储空间，当然你也可以在淘宝上购买5TB版本的教育账号。最终功能可以在下载中心进行bt下载、通过各大视频网站的链接进行下载，并直接传到Onedrive上，最后可以在手机或电脑通过视频流的方式直接观看视频。需要使用的工具 ubuntu18 VPS一台 Onedrive账号一个 (optional) 一个c端的可直连Onedrive的软件项目主页https://github.com/Mopip77/download_taskVPS搭建下载平台首先购买一台国外的VPS，这里为什么要国外的vps呢？主要是考虑到国外的资源一般国外的辅种人数会多一点，并且最为重要的是国外直传Onedrive会快非常多。 开放端口bt下载直接接入了aria2以及Aira-NG，感谢各位大佬的开发，因为使用了aira2，所以我们需要开放6800端口。并且需要通过web访问，所以还需要开启80端口。 获取token由于我们下载好的内容是直接传到Onedrive的，这里使用了一个rclone帮助我们完成上传的功能，因此我们需要rclone到onedrive的授权访问的token，我们先在本地下载好rclone，rclone主页。之后，在本地终端使用rclone authorize onedrive获取token，期间会通过浏览器登录你的onedrive账号，之后一串神秘代码会返回到终端，复制这段token。因为这个需要调用浏览器，所以必须使用本地来执行。复制这一串代码（两个大括号之内的东西，包括大括号）备用。 进入到VPS Shell，使用这个脚本部署一站式下载 #!/bin/bash# 该文件为自动部署脚本，但是测试使用的vps为ubuntu 18，其他种类或版本的linux系统不一定支持# env# 其中，除了ONEDRIVE_TOKEN必须设置，其他都有默认值，详情参见README.md# 应用IDAPP_ID=APP_PWD=# 应用密码# aria_prc的密码ARIA_RPC_PWD=# onedrive云上的同步根文件夹ONEDRIVE_BASE_PATH=# onedrive的to# ken，在本地使用rclone authorize &quot;onedrive&quot; 获取ONEDRIVE_TOKEN=&#39;必须配置&#39;# version 默认不指定版本号，缺省即使用latest#dl_api_version=&quot;:v0.0.1&quot;#dl_vue_version=&quot;:v0.0.1&quot;# 由于程序自带了环境变量的默认值，所以如果上方的配置项留空，那么就不传入该配置项# 该方法接收配置项项名，如果该配置项不为空(以APP_ID=me为例，传入APP_ID)，那么就返回 &quot;-e APP_ID=me&quot;, 如果(APP_ID=)，那么就不返回，docker也就不会传入该配置项fmt_docker_env() { env_name=$1 eval env_var=`echo &#39;$&#39;$env_name` if [ &quot;$env_var&quot; != &quot;&quot; ] then echo &quot;-e ${env_name}=${env_var}&quot; fi}apt update# nginx 部分apt install -y nginxsystemctl start nginxecho -e &#39;server { listen 80;location / { proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:3001; } location /api { proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:3000; }}&#39; &amp;gt; /etc/nginx/sites-enabled/defaultnginx -s reload# docker 部分apt install -y docker.io# 创建一个私有的局域网用于通信docker network create dl# 开启 redis dockerdocker pull redisdocker run -d \\ --network=dl \\ --hostname=redis \\ --name=redis redis# 开启 api dockerdocker pull mopip77/dl_api${dl_api_version}docker run -d \\ -e REDIS_ADDR=redis:6379 \\ -e ONEDRIVE_TOKEN=${ONEDRIVE_TOKEN} \\ `fmt_docker_env ARIA_RPC_PWD` \\ `fmt_docker_env APP_ID` \\ `fmt_docker_env APP_PWD` \\ `fmt_docker_env ONEDRIVE_BASE_PATH` \\ --network=dl \\ --hostname=dl_api \\ -p 3000:3000 \\ -p 6800:6800 \\ --name=dl_api mopip77/dl_api${dl_api_version}#开启 vue dockerdocker pull mopip77/dl_vue${dl_vue_version}docker run -d --network=dl \\ --hostname=vue \\ --name=vue \\ -p 3001:80 mopip77/dl_vue${dl_vue_version}# 由于api容器安装较慢，所以最后输出一下其日志，用于判断部署完成docker logs -f dl_api我们只需要配置APP_ID、APP_PWD也就是这个下载页面的用户名和密码ARIA_RPC_PWD这个是aira远程过程调用的密码，随便设置即可ONEDRIVE_BASE_PATH是Onedrive的保存路径，这个路径命名符合linux文件系统的规范最后就是ONEDRIVE_TOKEN，修改成刚刚获取到的token如果配置没有问题的话，端口也没有被占用（这里使用了3001,3000,6800,80），那么应该就成功了，尝试一下，使用浏览器访问http://&amp;lt;ip&amp;gt;/dl左边是aria，需要手动配置一下刚刚设置的rpc的密码右边是卡片式的下载任务，可以添加常见视频网站的视频，默认下载最高画质Bug: 有个问题是rclone中需要选择remote cloud storage的编号，这个编号可能会变化，所以可能会无法配置好rclone，此时需要进入docker container手动配置 you-get由于会根据网站视频源获取方法不同频繁更新，但是docker里是固定版本的，所以可能会导致下载错误，也需要进docker来手动更新，（这个以后应该写到docker的启动脚本中，不应该写到image中）Tips:有可能浏览器会自动跳转到127.0.0.1，请尝试更换浏览器，mac的safari不会有这种问题" }, { "title": "SpringProfile", "url": "/posts/SpringProfile/", "categories": "", "tags": "spring, profile", "date": "2020-07-24 00:00:00 +0800", "snippet": "基本内容这里就不介绍了，这里主要介绍一下profile文件的形式和如何指定。profile文件形式单体文件这是一般教程中最常使用的profile文件编写方式，最简单地就是使用yml格式实现---spring: profiles: devserver: port: 8081---spring: profiles: localserver: port: 8082---spring: profiles: active: local多profile文件以application-{profileName}.yml来创建多个profile配置文件，然后在application.yml中指定生效的profile即可这个在配置文件不多的情况下可以使用多profile folder这个不是spring支持的写法，而是使用了maven的profile以及maven决定如何引入resource文件到classpath下我们可以以一种特定文件名格式例如profile_{profileName}来创建不同profile的文件夹-resources (classpath) - profile_beta - profile_local - application.yml - log4j2.xml - sentry.properties - profile_prod - profile_test然后里面可以放各种配置文件（所以这个适合多种不同配置文件都需要迎合不同profile时使用）配置文件的起名方法需要依照在classpath下的起名方法起名（例如默认配置文件就是application.yml），原因最后说并且在pom.xml中指定各个profile以及生效的profile&amp;lt;profiles&amp;gt; &amp;lt;profile&amp;gt; &amp;lt;id&amp;gt;prod&amp;lt;/id&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;profileActive&amp;gt;prod&amp;lt;/profileActive&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;/profile&amp;gt; &amp;lt;profile&amp;gt; &amp;lt;id&amp;gt;local&amp;lt;/id&amp;gt; &amp;lt;activation&amp;gt; &amp;lt;activeByDefault&amp;gt;true&amp;lt;/activeByDefault&amp;gt; &amp;lt;/activation&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;profileActive&amp;gt;local&amp;lt;/profileActive&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;/profile&amp;gt;&amp;lt;/profiles&amp;gt;这里为了版面省略了两个文件夹，可以看到这里时默认生效local的profile还需要指定如何引入resource文件到classpath下&amp;lt;build&amp;gt; &amp;lt;resources&amp;gt; &amp;lt;resource&amp;gt; &amp;lt;directory&amp;gt;src/main/resources&amp;lt;/directory&amp;gt; &amp;lt;filtering&amp;gt;false&amp;lt;/filtering&amp;gt; &amp;lt;excludes&amp;gt; &amp;lt;exclude&amp;gt;profile_*/*&amp;lt;/exclude&amp;gt; &amp;lt;/excludes&amp;gt; &amp;lt;/resource&amp;gt; &amp;lt;resource&amp;gt; &amp;lt;directory&amp;gt;src/main/resources/profile_${profileActive}&amp;lt;/directory&amp;gt; &amp;lt;filtering&amp;gt;false&amp;lt;/filtering&amp;gt; &amp;lt;/resource&amp;gt; &amp;lt;/resources&amp;gt;&amp;lt;/build&amp;gt;这样就很清晰了，因为这四个profile文件夹都在classpath下，所以首先我们把所有profile_xxx的文件夹都排除之后我们再单独引入生效的profile的文件夹到classpath下，其中${profileActive}为maven的变量，也就是我们上面指定的local可以简单理解为把profile_local的所有文件复制到resources目录下，再把这四个profile文件夹删除，因此为什么文件夹内文件的命名需要按照默认命名方法命名就很好理解了最后验证一下，package后是不是把这些配置文件移动到了classpath下，检查一下jar包发现确实application.yml移动到了classpath下 BOOT-INF/classes/application.yml" }, { "title": "jackson使用说明", "url": "/posts/jackson%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/", "categories": "", "tags": "java, jackson", "date": "2020-07-23 00:00:00 +0800", "snippet": "引入首先说到jar包的引入，jackson分为三种jar包 core annotation databind由于databind依赖了core和annotation，所以只需要引入databind即可demo一个Pojo类@Datapublic class APojo { private int stuId; private String stuName; private Date date; private BPojo bPojo; private List&amp;lt;Integer&amp;gt; intList; private Map&amp;lt;Integer, String&amp;gt; map; private int[] intArr; private AEnum aEnum;}这里大致覆盖了大部分的java类型，额外的类型或者千层饼嵌套类型可以自己尝试使用Objectapper变换jsonString和objectAPojo li = new APojo(1, &quot;li&quot;, new Date(), new BPojo(&quot;zxcdv&quot;, 2), list, map, new int[]{1, 2}, AEnum.AA);ObjectMapper mapper = new ObjectMapper();String s = mapper.writeValueAsString(li);APojo aPojo = mapper.readValue(s, APojo.class);一个write一个read就可以覆盖80%的使用场景了，所以这里不是重点，重点是序列化后的格式如何？Tips (IMPORTANT):需要注意，使用反序列化必须有无参的构造函数，所以有@AllArgsConstructor那也必须要配对一个@NoArgsConstructor，否则反序列化时直接报错默认序列化格式对于上面的对象序列化的结果如下：{ &quot;stuId&quot;:1, &quot;stuName&quot;:&quot;li&quot;, &quot;date&quot;:1595515913865, &quot;intList&quot;:[ 56, 5 ], &quot;map&quot;:{ &quot;1&quot;:&quot;asdf&quot;, &quot;3&quot;:&quot;zxcb&quot; }, &quot;intArr&quot;:[ 1, 2 ], &quot;aenum&quot;:&quot;AA&quot;, &quot;bpojo&quot;:{ &quot;a1&quot;:&quot;zxcdv&quot;, &quot;b2&quot;:2 }}需要注意的一些点： Date会被转换成时间戳 List和array都是一样地用[item1, item2…]来表示 map和object一样都是用{“key”: value, …}来表示 enum的值是枚举的名称，而不是内部值（这里的内部值是一个int）最需要注意的一点是字段名称的转换：stuId -&amp;gt; stuIdbPojo -&amp;gt; bpojo看到这个转换规则是不是很懵逼？其实逻辑就是如果变量名最前面只有至多一个小写字母，那么最前面的所有大写字母都会变成小写，例如:aAAdd -&amp;gt; aaaddAAAdd -&amp;gt; aaaddaaAdd -&amp;gt; aaAddAAaDD -&amp;gt; aaaDD所以，如果不是全小写还是推荐使用@JsonProperty()注解来指定序列化的名称 有趣的是在gradle中使用@AllargsConstructor，然后使用全参的构造函数会报错，可能缺少什么配置，后续跟进常用的jackson annotation@JsonProperty这个应该是最常用的注解了，因为他涵盖了序列化名称，是否必须使用， 位置的索引，默认值，访问权限String value() default &quot;&quot;;boolean required() default false;int index() default -1;String defaultValue() default &quot;&quot;;JsonProperty.Access access() default JsonProperty.Access.AUTO;public static enum Access { AUTO, READ_ONLY, WRITE_ONLY, READ_WRITE; private Access() { }}序列化名称就是json中字段的名称，如果必须那么json反序列化时必须提供该字段否则报错 位置的索引则是字段在json中的位置（相对大小即可，无需一一紧靠，索引值越小排在越前面）默认值（预备字段，现在还不能使用）访问权限可以设置读、写、读写（反序列化，序列化，双向）@JsonIgnoreProperties这个可以指定需要忽略的字段，但是最常用的还是@JsonIgnoreProperties(ignoreUnknown = true)，如果不使用这个，那么如果json中包括pojo中不存在的字段，则反序列化时会直接报错。当然即便使用了，如果传入的字段的值属性有误，也会报错。其余的我们按照读写的使用区别来分类讨论读写@JsonIgnore直接在字段上使用，读写时都会忽略，不会写到json中，而生成obj时则是默认值。@JsonIgnoreProperties上面说了其最主要的使用方法，还可以在类上使用来一一指定需要忽略的字段@JsonIgnoreProperties（{“firstName”，“lastName”}）@JsonIgnoreType直接在类上使用，整个类都不会序列化和反序列化，例如我们将这个注释写在demo中的BPojo上，序列化的结果就没有bPojo@JsonAutoDetect这个属实没啥用，这个的使用场景是在没有getter、setter方法时，使用这个注解来自动侦测字段例如：@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.NON_PRIVATE)public class APojo { private int stuId; Date date;首先这个pojo没有setter和getter，然后有一个private和default的字段，我们这时候将filed可见性调整至非private，这样date就可以被序列化和反序列化。。。多此一举当然有多种类型可以自由组合：可见性： fieldVisibility，getterVisibility，isGetterVisibility，setterVisibility，creatorVisibility字段可见性：ANY, NON_PRIVATE, PROTECTED_AND_PUBLIC, PUBLIC_ONLY, NONE, DEFAULT;读@JsonSetter在json字段和java字段名不同的时候使用，作用在setter方法上，例如json为id，java为stuId，那我们可以：@JsonSetter(&quot;id&quot;)public void setStuId(int stuId) { this.stuId = stuId;}当然，我想不明白为什么不使用@JsonProperty@JsonAnySetter这个可能稍微有点用，我们之前说过，可能会传入不属于java的字段，我们可以使用@JsonIgnoreProperties来忽略他们，当然如果你需要记录一下这些额外字段时，你可以用这个注解配合一个map来接收这些kv@JsonIgnoreprivate Map&amp;lt;String, Object&amp;gt; properties = new HashMap&amp;lt;&amp;gt;();@JsonAnySetterpublic void set(String fieldName, Object value){ this.properties.put(fieldName, value);}public Object get(String fieldName){ return this.properties.get(fieldName);}创建一个map，设置一个setter方法，但是这个setter方法并不是设置properties的引用，而是put kv，并在这个set方法上使用@JsonAnySetter其次，这个map我们也不会传出去，所以使用@JsonIgnore去忽略他，有趣的是这难道不会在反序列化的时候无法写入吗？@JsonIgnore会让这个properties在反序列化时无法赋值，但是@JsonAnySetter指定的set方法其实是put方法，所以可以写入。@JsonCreator当没有setter或者无参构造函数时，你可以在构造方法上使用这个注解，反序列化时就可以使用有参的构造器来构建obj，但是需要指定每一个字段的json名，否则会报错@JsonCreatorpublic PersonImmutable( @JsonProperty(&quot;id&quot;) long id, @JsonProperty(&quot;name&quot;) String name) {@JsonDeserialize使用自定义的反序列化器，需要指定class，并且该类需要实现一个接口public class PersonDeserialize { public long id = 0; public String name = null; @JsonDeserialize(using = OptimizedBooleanDeserializer.class) public boolean enabled = false;}public class OptimizedBooleanDeserializer extends JsonDeserializer&amp;lt;Boolean&amp;gt; { @Override public Boolean deserialize(JsonParser jsonParser, DeserializationContext deserializationContext) throws IOException, JsonProcessingException { String text = jsonParser.getText(); if(&quot;0&quot;.equals(text)) return false; return true; }}其中泛型指定的是返回值（java字段中的），而jsonParser.getText()读取的是json的string value写介绍完了读相关的注解，写的部分注解即为读注解的逆操作，可以对照学习@JsonInclude这个指定了在何种情况下的字段才会导出@JsonInclude(JsonInclude.Include.NON_EMPTY)public class PersonInclude { public long personId = 0; public String name = null;例如指定了non_empty并且name为null的话，name就不会导出到json中。@JsonGetter这个就是@JsonSetter的孪生兄弟，作用在Getter方法上，导出到json中的字段为注解指定的字段。@JsonAnyGetter@JsonAnySetter是使用一个map接收所有json中unknown的字段，而@JsonAnyGetter则是摊平（flat）map中的字段private Map&amp;lt;Integer, String&amp;gt; map; @JsonAnyGetter public Map gettttt() { return map; }假如map中包括 {a:1, b:2}那么map中的元素也会和其他元素平级出现在json中，不过最好别用，万一重名咋整还有就是如果使用了@JsonAnyGetter那么必须使用@JsonAnySetter，否则序列化和反序列化是不可逆的，除非他们再重新拼出一个map传入@JsonPropertyOrder这个顾名思义是指定json中的字段顺序的，但是和@JsonProperty使用index不同，这个需要写在类上，并且显式声明字段的顺序@JsonPropertyOrder({&quot;name&quot;, &quot;personId&quot;})public class PersonPropertyOrder { public long personId = 0; public String name = null;}这样，那么就会出现在最前面@JsonRawValue直接输出原始值，有点像sql的${}重点使用场景就是如果一个字段String表示的是一段json文本，并且需要输出到json作为一个可读的json obj而不是一串字符串时使用。public class PersonRawValue { public long personId = 0; @JsonRawValue public String address = &quot;{ \\&quot;street\\&quot; : \\&quot;Wall Street\\&quot;, \\&quot;no\\&quot;:1}&quot;;}这样，序列化后就会直接生成一个json子对象{&quot;personId&quot;:0,&quot;address&quot;:{ &quot;street&quot; : &quot;Wall Street&quot;, &quot;no&quot;:1}}@JsonValue这个非常奇怪，调用序列化方法会生成一个自定义的字符串，类似toString方法@JsonValuepublic String toJson() { return stuName + &quot; de id is:&quot; + stuId;}之后我们调用writeAsString方法就会返回这个toJson的值，相当于我们要在这个方法中自行完成json字符串的拼接。。。 那我用你这个jackson干嘛。。。@JsonSerialize之前介绍了custom反序列化器，现在则是custom序列化器public class PersonSerializer { public long personId = 0; public String name = &quot;John&quot;; @JsonSerialize(using = OptimizedBooleanSerializer.class) public boolean enabled = false;}public class OptimizedBooleanSerializer extends JsonSerializer&amp;lt;Boolean&amp;gt; { @Override public void serialize(Boolean aBoolean, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException, JsonProcessingException { if(aBoolean){ jsonGenerator.writeNumber(1); } else { jsonGenerator.writeNumber(0); } }}尾巴自此，大部分的jackson注解已经记录完了，其实正常使用时基本上也就只能用到2、3个注解，因为需要额外的功能我们不需要添加注解，我们一般增加、减少java的字段即可。使用复杂的注解徒增复杂度，也就只有在做适配器的时候才可能使用一些复杂的注解。" }, { "title": "在线书库安装介绍", "url": "/posts/%E5%9C%A8%E7%BA%BF%E4%B9%A6%E5%BA%93%E5%AE%89%E8%A3%85%E4%BB%8B%E7%BB%8D/", "categories": "", "tags": "NAS, calibre", "date": "2020-05-19 00:00:00 +0800", "snippet": "最近在倒腾N1盒子，看看有什么有趣的应用，发现有一个在线书库（calibre-web），这是一个在线书库，可以上传、下载、管理书籍，最重要的是可以在线阅读。calibre就是大名鼎鼎的多平台的图书管理软件，不过我基本上只使用它转码然后发送到ipad的kindle客户端上，毕竟多平台同步功能是最为重要的，否则一本书如果只能在一台电脑上看那肯定看着看着就弃了，更别说电脑也不适合长时间阅读。其次，我觉得在线书库是家中nas的一个很合适的应用，相比于视频而言，nas不需要转码，如果需要在外网访问nas中的视频，那么nas则还需要一个GPU或者强一点的CPU，然后需要一个大带宽的代理服务器，这两点我的这个N1盒子都完全做不到，不过在线书库传输容量也不大，而且可以多点使用，同步阅读。安装过程首先我们可以在dockerhub中找到calibre-web的项目。发现下载最多的有三种，我这里推荐的是第一个linuxserver的项目，因为这个容量小，目前最新的docker image只有371MB，而和他同量级的第三个有1.11G，我这个n1盒子运行起来着实有点吃力，且不说第三个只支持x86结构的，我这个n1还不能用。拉取第一个linuxserver的calibre-web的镜像，如果网络不行可以拉取hub-mirror.c.163.com/linuxserver/calibre-web，基本上流行的镜像都能用网易的源拉取，当前更新不一定及时，例如这个就不是最新的。拉取完之后，我们可以看看官方介绍的安装、使用手册。可以看到，官方好心的帮我们完成了docker compose的编写，直接复制使用即可。并且对所有配置项都介绍了。当然，你需要注意几点：1、 为了使docker container中的运行用户获取宿主机中文件夹的权限，你需要使用id &amp;lt;你的用户名&amp;gt;查看并修改UID和GID，并且最好将宿主机中/config和/books的对应文件夹的权限改为7772、 运行后并不能直接使用，需要导入书库到/books文件夹中，这一点官方文档并没有提及，也是我安装时困扰我的一点，之后再说如何导入书库我们修改完docker-compose配置后可以直接运行，我的配置文件如下：第一次进入calibre-web界面会让你设置书库的位置，这个书库的位置就是/books文件夹，但是如果你没有导入书库那么肯定会报数据库找不到的错误。导入书库其实导入书库很简单，因为calibre-web使用的是calibre的数据库，那么我们只需要将设备中的calibre的书库文件夹复制到/books中即可。我本机mac上的calibre的书库文件夹放在了/Documents/calibre中，其中格式如图所示，所有书都以文件夹形式存放，数据库就是metadata.db这个文件，我们只需要将该文件夹内所有文件导入calibre-web的/books文件夹中即可。需要注意，一定要把所有文件导入进去，因为这里面的书籍信息都会存在于metadata.db中，如果你少传一两本书，后台的解析书籍的程序会报错，也无法配置成功。导入后，我们再输入书库位置，配置就生效了，然后使用官方教程中提到的管理员账户登录，账号：admin，密码：admin123，如果需要暴露在公网，第一时间修改默认密码。登录后你就能看到之前传入的那些书籍了。配置导入后还有一个重要点就是，admin用户并不能在线阅读，所以我们需要设置一个新用户，操作如下。点击首页右上角的管理，然后点击新建用户，按要求完成信息后需要勾选该用户的权限，我们至少把上传，下载，ebook viewer和删除的权限给勾上，这样该用户就能自由地在该软件中使用了。还有，除了用户的上传权限要设置，该软件默认全局是禁用上传的，所以我们需要全局开启一下上传功能。全局功能设置在管理 -&amp;gt; 修改基本配置 -&amp;gt; 特性配置中勾选允许上传，其余还有很多额外功能，自行摸索。最后，需要注意的是该软件所支持的在线阅读格式支持pdf和epub，不支持mobi，其他格式我没有测试，尽量上传这两种格式的书籍。还有，该软件并不支持用户阅读进度，但是浏览器会保存你的进度，不过你想在电脑上阅读后，然后用手机接着阅读，只能使用书签功能。其次，不支持批注功能，所以尽量用这个看看小说，技术类书籍还是用pdf阅读器看，推荐一下pdf expert可多平台然后书源连接到onedrive，可以同步批注。" }, { "title": "cli视频网站解析下载软件横评", "url": "/posts/cli%E8%A7%86%E9%A2%91%E4%B8%8B%E8%BD%BD%E8%BD%AF%E4%BB%B6%E6%A8%AA%E8%AF%84/", "categories": "", "tags": "下载", "date": "2019-11-07 00:00:00 +0800", "snippet": "最近做了个一站式下载的网页，套用了AriaNg(HTTP,BitTorrent,SFTP,FTP)以及自己做的任务式(支持历史记录，重启，查看输出)视频网站的下载(使用you-get)。但是早在今年上半年you-get关闭了issue，并且更新很慢，所以我还是来比较一下现在比较流行的几个cli解析视频网站下载软件的覆盖情况入场选手老牌王者youtube-dl，正值当年you-get，后起之秀annie选手介绍youtube-dl已经有了多年历史，并且在国外玩的是风生水起，看名字也知道之前是下载youtube视频起家的，然后由于用户的需求更加广泛，所以后来支持了更多的视频网站解析，那么在国内它的使用情况又如何呢？除此之外，youtube-dl不仅安装简单(直接使用apt就能安装)，还有丰富的使用说明，足以让你好好学一下午(即不易上手)！you-get是我使用的最多的一个下载软件，由国人开发所以对国内网站支持较好，github上stars数也很多，但是最近关闭了issue，并且更新缓慢，我这次比较主要目的就是看看能否找到更好的替代品。并且安装需要依赖python，更重要的是不内置ffmpeg，对于分段视频(需要拼接)、youtube高清视频(视频音频分离，需要拼接)，如果没有安装ffmpeg，那么这类视频都不能很好地支持。annie之前没听过，这次搜罗到的，stars有8k，并且使用go开发，功能简单(易上手)，希望能有个好的表现。比赛项目虽然每个软件基本都覆盖了数十个国内外网站，但我还是会根据我自己的使用情况来选择一些我常用的或者是非常主流的视频网站下面表格如果打勾表示支持，并且支持最高清晰度其中，每一项都没有做大量测试，所以只能做个大概参照，例如仅xx格式可能只是对测试用例的支持情况   youtube-dl you-get annie 备注 B站(视频) ✔(仅flv) ✔(flv+mp4) ✔(flv) 除了annie，都不支持大会员更高清晰度 B站(番剧) ✘ 部分支持 部分支持 支持的条件不是很清楚，可能是喜久厌新 斗鱼(直播流、视频回放) ✘ ✘ ✘ 自从斗鱼更改了加密方式已经很久不能用了 爱奇艺 ✘ 受限支持 ✔ you-get:最高720p，由于使用ts流，导致需要安装ffmpeg才能下载 腾讯 ✘ 720p ✔   微博视频 ✘ ✘ ✘ 虽然都不支持，但是获取微博的直链很简单，可自己操作 Youtube ✘ ✔ ✔ youtube-dl不支持youtube？我崩溃了，是不是我的测试方法有问题… 我最常用的也就上面几个，多了我也不测了，单看上面几个项目的结果基本上能得出一个结论了，不说了，我去部署annie了。。。尾巴测试完这些以后，我感觉确实对于广泛视频网站的支持和视频网站频繁地更新直链获取规则，加密方法等等情况而言，单凭开发者一个人的努力是远远不够的。you-get因此也关闭了issue，采取更为激进的使用pull request来提交你的issue，对于你不满足的点你可以自行完善并让该项目变得更好，希望大家也能多多为开源项目贡献自己一份力。除此之外我还要表扬一下annie的界面和进度条，确实五颜六色的而进度条动起来也是十分带感的，和常见的进度条不同这两个库分别是color和process bar补充在使用过程中发现其实annie也是依赖ffmpeg的，并且在vps上使用annie默认下载方法速度很慢，可以修改-cs参数，修改http chunk的大小，默认单位MB，经测试3～5比较合适。另外annie是默认不下载字幕文件的，使用-C参数开启(但是youtube的好像没效果)。发现一个问题，在下载youtube的高清视频时，下载的音频视频是分开的，需要使用ffmpeg合并，但是annie非常慢，而you-get非常快，之后我去看了一下它们的源码，原因如下：annie使用的是ffmpeg -i xx.mp4 -i xx.mp3 -c:v copy -c:a aac -strict experimental output的格式，需要将音频转换为aac，所以非常慢func MergeAudioAndVideo(paths []string, mergedFilePath string) error { cmds := []string{ &quot;-y&quot;, } for _, path := range paths { cmds = append(cmds, &quot;-i&quot;, path) } cmds = append( cmds, &quot;-c:v&quot;, &quot;copy&quot;, &quot;-c:a&quot;, &quot;aac&quot;, &quot;-strict&quot;, &quot;experimental&quot;, mergedFilePath, ) return runMergeCmd(exec.Command(&quot;ffmpeg&quot;, cmds...), paths, &quot;&quot;)}而you-get则是先使用ffmpeg -i xx -i xx -c copy output，也就是音频视频的格式同时复制，这样会快很多，并且如果失败的话(如果是mp4格式)，还是会调用ffmpeg -i xx.mp4 -i xx.mp3 -c:v copy -c:a aac -strict experimental outputdef ffmpeg_concat_av(files, output, ext): print(&#39;Merging video parts... &#39;, end=&quot;&quot;, flush=True) params = [FFMPEG] + LOGLEVEL for file in files: if os.path.isfile(file): params.extend([&#39;-i&#39;, file]) params.extend([&#39;-c&#39;, &#39;copy&#39;]) params.append(output) if subprocess.call(params, stdin=STDIN): print(&#39;Merging without re-encode failed.\\nTry again re-encoding audio... &#39;, end=&quot;&quot;, flush=True) try: os.remove(output) except FileNotFoundError: pass params = [FFMPEG] + LOGLEVEL for file in files: if os.path.isfile(file): params.extend([&#39;-i&#39;, file]) params.extend([&#39;-c:v&#39;, &#39;copy&#39;]) if ext == &#39;mp4&#39;: params.extend([&#39;-c:a&#39;, &#39;aac&#39;]) params.extend([&#39;-strict&#39;, &#39;experimental&#39;]) elif ext == &#39;webm&#39;: params.extend([&#39;-c:a&#39;, &#39;opus&#39;]) params.append(output) return subprocess.call(params, stdin=STDIN) else: return 0所以我们可修改下载脚本，如果是youtube的链接就使用you-get下载。" }, { "title": "aria2c常用命令", "url": "/posts/aira2c%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/", "categories": "", "tags": "aria", "date": "2019-10-06 00:00:00 +0800", "snippet": "在mac下使用bt下载速度相同情况下会比windows慢很多。遂使用aria，一开始使用网页版AriaNg，速度也是启动地很慢，并且无法选择下载特定的文件。所以直接使用命令行。确实下载启动快很多。-d, –dir=DIR下载到哪个目录类似: D:\\-o, –out=FILE下载保存的文件名-s, –split=N多线程下载文件 1-* 默认5-c, –continue[=true|false]断点续传-i, –input-file=FILE批量下载文本中所有URL比如aria2c -i uris.txt-j, –max-concurrent-downloads=N设置同时下载的文件数 1-* 默认5简单篇：一般使用使用 aria2 下载文件，只需在命令后附加地址即可。比如我们下载QQ如：aria2c http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe如果需要重命名的话加上–out或者-o参数aria2c –out=QQ http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exearia2c -o QQ http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe分段下载利用 aria2 的分段下载功能可以加快文件的下载速度，对于下载大文件时特别有用。为了使用 aria2 的分段下载功能，你需要在命令中指定 x 选项。如：aria2c -x 2 http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe-x配合-s 和-j可更好使用如:aria2c -s 2 -x 2 -j 10 http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe这将使用 2 个连接来下载该文件。s 后面的参数值介于 1~5 之间，你可以根据实际情况选择。PS：-s这个参数的意思是使用几个线程进行下载，-x是最大使用几个线程下载，-j就是同时下载几个文件。（这个是我的理解对不对不清楚）断点续传在命令中使用 c 选项可以断点续传文件。如：aria2c -c http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe验证文件是否正确：有的时候为了确认下载的文件时候正确或是否被人修改需要验证md5码，这里可以使用一下命令aria2c -c -x16 -s20 -j20 –checksum=md5=xxxxxxxxxxxxx http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe其中md5可以修改成你需要的校检方法，后面的xxxxx改成正确的校检码。高级篇bt下载aria2c ‘xxx.torrnet‘aria2c ‘磁力链接’列出种子内容aria2c -S target.torrent下载种子内编号为 1、4、5、6、7 的文件aria2c –select-file=1,4-7 target.torrent设置bt端口aria2c –listen-port=51413 ‘xxx.torrent’设置dht端口aria2c –dht-listen-port=51413 ‘xxx.torrent’有的文件下载是需要引用页，我们可以这样输入如aria2c –referer=http://im.qq.com/qq/2011/ ‘http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe’有时我们需要错误信息时要加上–log如aria2c –log=xxx –referer=http://im.qq.com/qq/2011/ ‘http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe’限速下载单个文件最大下载速度：aria2c –max-download-limit=300K -s10 -x10 -j10 ‘http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe’整体下载最大速度：aria2c –max-overall-download-limit=300k -s10 -x10 -j10 ‘http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe’下载需要cookie验证的文件aria2c –header=“Cookie:cookie名称=cookie内容“ ‘http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe‘或aria2c –load-cookies=cookie文件 ‘http://dl_dir.qq.com/qqfile/qq/QQ2011/QQ2011.exe‘其中cookie文件需要自己手动导出，导出方法为chrome用户需使用此扩展，firefox需使用此扩展，使用扩展导出离线页面cookie命名为cookie_text当然这样使用很麻烦所以我们可以通过alias来进行简化：alias xunlei=’aria2c -s 6 -c –load-cookies=/home/user/cookie_text’（Ubuntu系统需要把此命令添加进.bashrc文件中）以后使用需要此cookies时只要使用下面命令即可xunlei “下载链接” -o xxx好了，常用的几个命令就介绍到这里了，更多的使用方法可以使用man aria2c和aria2c -h 查看。" }, { "title": "JWT(json web tokens)简介", "url": "/posts/JWT(json-web-tokens)%E7%AE%80%E4%BB%8B/", "categories": "", "tags": "jwt", "date": "2019-08-16 00:00:00 +0800", "snippet": "我们知道我们经常使用的session+cookie实现http的认证有一些缺点。 由于session存储在服务器，并且对每个session服务器都会在jvm中分配一部分内存，在单机模式下，所以一旦用户量过多，那么有可能导致内存不足的问题。 使用服务器集群或者跨域时又需要满足多台服务器共享session的问题，横向扩展性不好。所以索性服务器就不存session信息了，全部存储在客户端里，每次访问服务器都附带该信息即可。详细介绍：http://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html" }, { "title": "How to create a map[string] [2]int in Go?", "url": "/posts/How-to-create-a-map-string-2-int-in-Go/", "categories": "", "tags": "go", "date": "2019-08-12 00:00:00 +0800", "snippet": "在编写go的时候碰到了个问题，我在创建map[string][2]int想做个key(string)，value(pair)的map时，发现创建没问题。当我使用a[&quot;abc&quot;][0] = 1时，报错了。Question: a := map[string][5]int a[“bb”] = [5]int{1,2,3} a[“bb”][1] = 5. // ERROR, 如果value是struct的话也是无法直接修改里面的成员变量的简而言之就是,map的value是无法寻址的,因为可能出现删除键后又放回的错误(不太懂),但是如果value值本身是引用类型则可以直接修改, 否则可以直接声明为map of pointer官方解释:The two cases really are different. Given a map holding a struct m[0] = sis a write. m[0].f = 1is a read-modify-write. That is, we can implement m[0] = sby passing 0 and s to the map insert routine. That doesn&#39;t work for m[0].fInstead we have to fetch a pointer, as you suggest, and assign through the pointer.Right now maps are unsafe when GOMAXPROCS &amp;gt; 1 because multiple threads writing to themap simultaneously can corrupt the data structure. This is an unfortunate violation ofGo&#39;s general memory safeness. This suggests that we will want to implement apossibly-optional safe mode, in which the map is locked during access. That will workstraightforwardly with the current semantics. But it won&#39;t work with your proposedaddition.That said, there is another possible implementation. We could pass in the key, anoffset into the value type, the size of the value we are passing, and the value we arepassing.A more serious issue: if we permit field access, can we justify prohibiting methodaccess? m[0].M()But method access really does require addressability.And let&#39;s not ignore m[0]++ m[0][:]参考链接：https://stackoverflow.com/questions/38477567/how-to-create-a-mapstring-2int-in-go" }, { "title": "gomod简介", "url": "/posts/gomod%E7%AE%80%E4%BB%8B/", "categories": "", "tags": "go", "date": "2019-08-11 00:00:00 +0800", "snippet": "gomodgomod是go 1.1之后引入的一个模块化软件本身go开发者的想法是希望将go的项目全部放入$GOPATH/src，同时下载的第三库也是放置于此，又因为在¥GOPATH/src下任何工程都可以互相导入，所以势必会引起冲突，引入gomod让我们可以在任何文件夹下运行go程序比如python，下载的所有第三方库都都放在site-package，所以我们也可以$GOPATH/src作为第三方库的下载文件夹，然后使用gomod，在其他任意文件夹下创建go工程（有趣的是，如果在$GOPATH/src下的工程使用gomod还会报错），这是开发者有意而为之的，当然也可以通过额外设置允许它，但是吃力不讨好极速入门:~/test $~/test $ go mod init hahago: creating new go.mod: module haha~/test $ cat go.modmodule hahago 1.12在test目录下使用go mod init &amp;lt;mod_name&amp;gt;新建go.mod文件，在此文件夹使用go env可以发现gomod被置为了~/test，然后go.mod只有一行module名称和go的版本号go.mod不需要自己手动编写，在build或者run的使用会自动创建。使用ide或者vscode能在文件中使用import时就自动更新同时在编译后还会产生一个go.sum文件，这个文件记录了所依赖项目的版本" }, { "title": "Docker的一些坑", "url": "/posts/Docker%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/", "categories": "", "tags": "linux, docker", "date": "2019-08-03 00:00:00 +0800", "snippet": "docker编译go的时候无法下载golang.org/x/crypto这个问题着实有点操蛋,在本机上我是先mkdir $GOPATH/golang.org/x/crypto, 用github.com/golang/crypto的内容直接替换的但是在容器的编译中我也尝试过这招,但是不仅麻烦而且最后还没成功,于是我发现了GO自带了PROXY, 所以用一个代理服务(go仓库代理并非网络代理)直接编译就行GOPROXY=&quot;https://goproxy.io&quot; go build xxxalpine版本的容器不带git(或其他软件)为了缩减最终image的大小,我们可能会选择alpine版本的image,但是它基本上是最简安装,所以我们需要安装软件,以git为例在国外服务器的情况下可以直接用apk add git安装git, apk是alpine自带的包管理软件 添加软件用的是add但是在国内基本上连不上alpinelinux.org, 在dockerfile中添加RUN sed -i &#39;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&#39; /etc/apk/repositories 替换成阿里云的镜像站,然后再安装gitgo无法编译在使用golang:1.12-alpine3.10时出现了这些问题 该镜像GOROOT=/usr/local/go GOPATH=/go如果将源码文件夹传入$GOROOT/src/mycode 则会抛出类似/usr/local/go/src/giligili/server/router.go:8:2: non-standard import &quot;github.com/gin-gonic/gin&quot; in standard package &quot;giligili/server&quot;的错误说明GOROOT只能存放标准包,并且都不能导入非标准包如果将源码文件夹传入$GOPATH/src/mycodeapi/main.go:11:2: cannot find package &quot;gopkg.in/go-playground/validator.v8&quot; in any of: /usr/local/go/src/gopkg.in/go-playground/validator.v8 (from $GOROOT) /go/src/gopkg.in/go-playground/validator.v8 (from $GOPATH)提示无法找到github的包…不知道为什么最终解决方法使用gomod,然后随便放在一个非$GOROOT $GOPATH的文件夹下编译即可" }, { "title": "Docker快速上手", "url": "/posts/Docker%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/", "categories": "", "tags": "linux, docker", "date": "2019-08-03 00:00:00 +0800", "snippet": "安装官网教程安装docker-ce也可以直接apt安装docker-io(早期版本)国内修改镜像源修改或新建/etc/docker/daemon.json{ &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]}这是docker-cn的源,也可以在网上找到网易等最后重启一下service docker restart启动一个容器docker run [:]如果没有会自动帮你pull-p 9000:80将宿主机的9000端口映射到容器的80端口上-v :将宿主机的src目录或文件夹映射到容器的dest-it交互式启动容器Build一个镜像首先要编写DockerfileFROM golang # 基础的镜像,由于需要go环境所以用golang,也可用alpine,ubuntu等等ADD . /usr/local/api_server # 将本机当前文件下下的内容复制到容器的/usr/local/api_server下, 并且还可以复制网络的内容COPY ./ /usr/local/abc_server # 只能拷贝本机内容到容器目录# 注意,以上两种复制都可以自动创建文件夹,但是如果源路径为本机的地址的话,必须是当前目录包括子目录,不能用外部目录WORKDIR /usr/local/api_server # 工作路径,由于我们可能会在刚刚上传的go源代码文件夹下操作,所以可以设置到此,不然在下面的RUN命令需要每一条都cd一下RUN go build -o my_server # 执行cmd命令(在WORKDIR下或者默认目录)ENTRYPOINT [&quot;my_server&quot;] # 执行入口上面是一个最简单的go的dockerfile然后我们需要build它在dockerfile的目录下执行docker build -t my_image:v0.0.1 my_image为镜像名, v0.0.1为tag然后就能在docker images中看见它docker registry类似github 可以直接上传镜像注意: 其实一个docker image的路径是[domain/][namespace/]repository:tag由于默认是docker hub, 所以可以省略domain, 但是如果需要上传,则需要加上namespace, 但这也是默认上传到docker hub阿里云 docker registryhttps://cr.console.aliyun.com/repository如使用阿里云的docker registry, 则需要配好命名空间(类似github的用户名,但是一个人最多可以有5个)和仓库然后登录上传即可登录sudo docker login --username=xxx registry.cn-hangzhou.aliyuncs.com上传docker push registry.cn-hangzhou.aliyuncs.com/namespace/image:[镜像版本号]所以如果使用的不是docker hub, image每个字段必须全部写清楚使用web可视化管理docker在服务器运行的docker可能很多,如果每次需要重新ssh连接后重新启动,或者服务挂了也需要自己手动重启很是麻烦所以可以使用portainer.io来管理 Install docker volume create portainer_datadocker run -d -p 8000:8000 -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer 这是可以看到开了一个volume用于存储portainer的配置,并且传了个/var/run/docker.sock容器有了这个就赋予了最高权限可以控制其他容器的启动关闭,这也是这个项目的最重要的基础 登录:9000, 注册好以后选择local模式 连接私有docker registry选择registries,新建一个(如果需要的话),注意dockerhub的官方registry url为registry.hub.docker.com 使用Stacks(docker-compose)部署docker容器编写容器的yaml配置示例(docker hub私有仓库):```yamlversion: ‘2’ # portainer只支持2版本的docker-compose services: nginx: # 服务名称,可随便起 image: registry.hub.docker.com/mopip77/giligili:v0.0.1 #镜像地址,如果是dockerhub的private仓库或者第三方registry的需要写全url,如果是dockerhub的官方public仓库则可以省略命名空间 restart: always # 服务挂后重启策略 ports: # 端口映射数组 - 3001:80mysql:我们知道,docker是最佳实践是无状态的,所以一旦重启,mysql的数据就会丢失,redis同理我们需要额外配置volume(起名为mysql_data)```yamlversion: &#39;2&#39;services: mysql: image: mysql volumes: - mysql_data:/var/lib/mysql # redis是 /data environment: MYSQL_ROOT_PASSWORD: &quot;!uaKhy53$abRzU6t&quot; restart: always ports: - 9006:3306别忘记mysql8.0更换了密码算法,所以navicat等无法连上,需要docker exec -it mysql_mysql_1 bash(mysql_mysql_1为运行中的mysql container的名字)进入容器更改数据库, 如何更改见mysql笔记使用docker容器进程访问另一个docker的mysql由于是跨docker访问,本质上是无法做到的,但是由于共用了同一台宿主机,所以可以通过暴露mysql docker的端口到宿主机的端口,再让其他docker进程访问宿主机的该端口注意,此时不能使用127.0.0.1:3306,因为这是docker的本机地址,而不是宿主机的本机地址,所以我们可以通过ifconfig找到docker0的ip(此ip段用于和容器组网通信),使用此ip即可如果是服务器的话可以直接使用内网ip当然服务器也可以将数据库端口暴露在公网上,然后通过公网ip,走一个来回访问到数据库,这样最简单,但是需要暴露数据库,非常非常非常不推荐,我之前用的mongodb就因为暴露在端口并且那个版本有漏洞服务器就被黑了.不仅是服务,命令行的mysql也能连接mysql -u root -h &amp;lt;docker0_ip | 服务器内网ip&amp;gt; -P &amp;lt;数据库映射到主机的端口号&amp;gt; -p" }, { "title": "Hive笔记", "url": "/posts/Hive%E7%AC%94%E8%AE%B0/", "categories": "", "tags": "hive", "date": "2019-07-20 00:00:00 +0800", "snippet": "Hive分区和桶的概念MapReduce 中的两表 join 几种方案简介Hive UDF开发指南MapReduce 排序：次排序（Secondary sort）Hadoop 里MapReduce里 实现多个job任务 包含（迭代式、依赖式、链式）Map和Reduce个数设置问题" }, { "title": "mysql8由于更换密码算法NaviCat连不上", "url": "/posts/mysql8%E7%94%B1%E4%BA%8E%E6%9B%B4%E6%8D%A2%E5%AF%86%E7%A0%81%E7%AE%97%E6%B3%95NaviCat%E8%BF%9E%E4%B8%8D%E4%B8%8A/", "categories": "", "tags": "mysql", "date": "2019-06-10 00:00:00 +0800", "snippet": " 进入mysql 设置权限(此处为root用户) mysql&amp;gt; grant all PRIVILEGES on *.* to root@&#39;%&#39; WITH GRANT OPTION;Query OK, 0 rows affected (0.01 sec) 更新密码算法```mysqlmysql&amp;gt; grant all PRIVILEGES on . to root@’%’ WITH GRANT OPTION;Query OK, 0 rows affected (0.01 sec)mysql&amp;gt; ALTER user ‘root’@’%’ IDENTIFIED BY ‘123456’ PASSWORD EXPIRE NEVER;Query OK, 0 rows affected (0.11 sec)mysql&amp;gt; ALTER user ‘root’@’%’ IDENTIFIED WITH mysql_native_password BY ‘123456’;Query OK, 0 rows affected (0.11 sec)mysql&amp;gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.01 sec)```" }, { "title": "crontab和notify-send不可共用问题", "url": "/posts/crontab%E5%92%8Cnotify-send%E4%B8%8D%E5%8F%AF%E5%85%B1%E7%94%A8%E9%97%AE%E9%A2%98/", "categories": "", "tags": "crontab, linux, notify-send", "date": "2019-04-16 00:00:00 +0800", "snippet": "因为notify-send是一个GUI程序并且直接与DBUS通信，而crontab执行后台程序所以在crontab中调用是没有效果的。只有设置环境变量以后程序才能联系桌面通知程序的绘画总线地址，从而起作用。在Mint19或Ubuntu18.04中，只需手动为cron作业提供DBUS_SESSION_BUS_ADDRESS=&quot;unix:path=/run/user/$(id -u)/bus&quot;即可。但该套接字实际上并不存在在Mint 18或Ubuntu 16.04上，但是可以编写脚本实现将该脚本命名为cron-notify放在/usr/bin下，并给其授权chmod +x cron-notify, 当然在Mint19(本机环境)上也能起作用#!/bin/shif [ -z &quot;$DBUS_SESSION_BUS_ADDRESS&quot; ]; then if [ -z &quot;$LOGNAME&quot; ]; then EUID=$(id -u) else EUID=$(id -u &quot;$LOGNAME&quot;) fi [ -z $EUID ] &amp;amp;&amp;amp; exit if [ -S /run/user/$EUID/bus ]; then export DBUS_SESSION_BUS_ADDRESS=&quot;unix:path=/run/user/$EUID/bus&quot; else SESSION=$(loginctl -p Display show-user &quot;$LOGNAME&quot; | cut -d= -f2) [ -z &quot;$SESSION&quot; ] &amp;amp;&amp;amp; exit LEADER=$(loginctl -p Leader show-session &quot;$SESSION&quot; | cut -d= -f2) [ -z $LEADER ] &amp;amp;&amp;amp; exit OLDEST=$(pgrep -o -P $LEADER) [ -z $OLDEST ] &amp;amp;&amp;amp; exit export $(grep -z DBUS_SESSION_BUS_ADDRESS /proc/$OLDEST/environ) [ -z &quot;$DBUS_SESSION_BUS_ADDRESS&quot; ] &amp;amp;&amp;amp; exit fifinotify-send &quot;$@&quot;参考https://forums.linuxmint.com/viewtopic.php?t=279095" }, { "title": "shell常用命令手册", "url": "/posts/shell%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%89%8B%E5%86%8C/", "categories": "", "tags": "linux", "date": "2019-02-27 00:00:00 +0800", "snippet": "trick command# 获取当前文件绝对路径curPath=$(cd `dirname $0`; pwd)# 判断当前用户是否为root用户user=$(env | grep USER | cut -d &quot;=&quot; -f 2)# 字符串A包含字符串Bif [[ &quot;$A&quot; =~ &quot;$B&quot; ]]# ${var##*/}字符串截取# 使用正则提取子串echo here365test | sed &#39;s/.*ere\\([0-9]*\\).*/\\1/g&#39; # 输出365# 其中s表示替换，\\1表示用第一个括号里面的内容替换整个字符串, sed支持*，不支持?、+，不能用\\d之类，正则支持有限。# 变量默认值 如果a有变量就是a的值，否则是1 同理${a:--1}才是-1${a:-1} # 判断变量是否存在, 如果变量var存在就输出var，否则输出&quot;&quot;，和${var:-}的区别在于，var不存在前者不会报错，后者会报错if [ -z/-n ${var:+} ]; thenfi# 文件按行读出常规可能使用for line in `cat xx`,但是这样的问题在于如果一行中有空格则会变成多个变量进入循环，所以请使用cat xx | while read linedo echo ${line}done其实read非常实用，除了它本身的功能，最好用的就是循环赋值了，上面也展示了，当然还可以为多个变量同时赋值，例如awk获取了两个字段read v1 v2 &amp;lt;&amp;lt;&amp;lt; `cat xx | awk &#39;{print $1, $2}&#39;`空格会将一行拆分成多行正是因为系统默认分隔符IFS(内部字段分隔符internal field separator)，其默认是空格，\\t或\\n。所以如果我们修改IFS也能达到按行拆分的效果。好处在于“我在go调用cmd命令时read命令不起作用！”OLD_IFS=&quot;$IFS&quot;IFS=$&#39;\\n&#39;xxxxxIFS=$OLD_IFS其中首尾两行用于恢复默认IFS，如果不需要也可以不写字符串分割使用read也非常方便, 可以通过IFS自定义分隔符,其中IFS在while scope内部定义，也不会影响到全局的IFS-r 会对\\n等转义字符保留\\，-a表示作为数组读入while IFS=&quot;$delimiter&quot; read -ra readLines; do for line in &quot;${readLines[@]}&quot;; do xxx donedone &amp;lt;&amp;lt;&amp;lt; &quot;$string&quot;# 遍历文件夹下所有文件，但是带有空格，和上面的一样都是空格在捣乱，这里可以使用和上面一样的方法，也可以使用先替换再替换回来的方法symbol=&quot;觉d怼e部z科k恁&quot; # 选择一个绝对不可能出现的短语for file in `ls xx | sed &#39;s/ /&#39;&quot;${symbol}&quot;&#39;/g&#39;`do realFileName=`sed &#39;s/&#39;&quot;${symbol}&quot;&#39;/ /g&#39; &amp;lt;&amp;lt;&amp;lt;$file` # realFileName就是包含空格的真正文件名done# 嵌套变量可使用eval读出, 用于传入一个环境变量本身的名字，然后获取环境变量的真实值a=&quot;cat&quot; b=&quot;a&quot; # 传入beval tmp=`echo &#39;$&#39;$b` # eval会多次扫描，第一次-&amp;gt;echo $a，第二次-&amp;gt;catecho $tmp # 结果就是cat关于更多eval：https://www.cnblogs.com/huzhiwei/archive/2012/03/14/2395956.html关于shell的并发和管道控制 https://blog.csdn.net/dubendi/article/details/78931979对于自动化或者测试来说，我们在执行程序时可能会需要键盘输入，使用expect可以很方便地通过判断程序输出来控制输入，实现自动化。https://www.jellythink.com/archives/373shell 编程 数组bash支持一维数组（不支持多维数组），并且没有限定数组的大小。 array_name=(value0 value1 value2 value3)# 获得数组所有元素${array_name[@]} 或 ${array_name[*]}# 获得数组长度${#array_name[@]}# 取得数组单个元素的长度lengthn=${#array_name[n]} 循环# 步进{1..10} 或 $(seq 1 10){1..10..2} 或 $(seq 1 2 10) # 步长为2# 其中所有;do都改成下行写do不要;# for 循环for 变量名 in 列表;do 循环体done# whlie 循环while CONDITION; do 循环体done 参数$0 Shell本身的文件名$1 Shell的第一个位置参数,一直到$9;当n&amp;gt;=10时,需要使用${n}来获取参数$# 传递到脚本的参数个数$* 以一个单字符串显示所有向脚本传递的参数$$ 脚本运行的当前进程ID号$! 后台运行的最后一个进程的ID号$@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。$- 显示Shell使用的当前选项，与set命令功能相同。$? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。最后一个参数不能使用${$#},需要使用${@: -1},并且中间的空格是必须的,或者是${!#}。但是如果没有参数，那么第一种是空串，而第二种则是相当于$0，也就是脚本名，所以推荐使用第一种。 比较# 字符串比较(前六个也可用于数字比较)-eq 等于-ne 不等于-gt 大于-lt 小于-le 小于等于-ge 大于等于-z 空串= 两个字符相等!= 两个字符不等-n 非空串=~ 左边字符串包含右边字符串# 文档比较 -e filename存在-d filename为目录-f filename常规文档-L filename为符号链接-r filename可读-w filename可写-x filename可执行bash编程常用技巧the-art-of-command-linebash严格模式，将这两行放在开头#!/bin/bashset -euo pipefailIFS=$&#39;\\n\\t&#39;bash script执行加锁if ! (set -o noclobber ; echo &amp;gt; /tmp/global.lock) ; then exit 1 # the global.lock already existsfi# ... remainder of script ...shell check冒号的妙用在linux中冒号(:)常用来做路径的分隔符(PATH)。其实，冒号(:)在Bash中也是一个内建命令，它啥也不做，是个空命令。常见作用如下1、占位符比如在编写脚本的过程中，某些语法结构需要多个部分组成，但开始阶段并没有想好或完成相应的代码，这时就可以用:来做占位符，否则执行时就会报错。if [ &quot;today&quot; == &quot;2011-08-29&quot; ]; then : else : fi 2、写注释，但是一般不这样写，就不举例了3、清空文件:&amp;gt;filename4、缺省值echo ${var:-DEFAULT}https://www.cnblogs.com/ChinaGo/p/9910747.htmlawkawk是行处理器: 相比较屏幕处理的优点，在处理庞大文件时不会出现内存溢出或是处理缓慢的问题，通常用来格式化文本信息特殊要点:$0 表示整个当前行$n 每行第n个字段NR 每行的记录号，多文件记录递增…分隔符:awk -F&quot;:&quot; &#39;{print $1}&#39; filename 以:为分隔符输出每行分割后第一项 awk -F: &#39;{print $1; print $2}&#39; filename 将每一行的前二个字段，分行输出 awk -F: &#39;{print $1,$3,$6}&#39; OFS=&quot;\\t&quot; filename 输出字段1,3,6，以制表符作为分隔符 判断语句:awk -F: &#39;{if($1~/mail/) {print $1} else {print $2}}&#39; filename awk -F: &#39;NR==5{print}&#39; filename 显示第5行 其中匹配方法有: //纯字符匹配 !//纯字符不匹配 ~//字段值匹配 !~//字段值不匹配 ~/a1|a2/字段值匹配a1或a2 条件表达式: == != &amp;gt; &amp;gt;= &amp;gt; &amp;lt; 需要使用shell中的变量只需要使用-v参数，例如shell中有一个参数num=2awk -v inner_num=${num} &#39;NR==inner_num{print $1}&#39;，但是需要注意，如果num中包含/符号则会报错，需要用双引号括起来sedhttps://www.cnblogs.com/maxincai/p/5146338.htmljq详细文档可以看https://stedolan.github.io/jq/manual/说一个用例，获取一个数组中每个元素的id，并生成bash中的array# @sh =&amp;gt; 输入经过转义，适合在 POSIX shell 的命令行中使用。如果输入是数组，则输出将是一系列以空格分隔的字符串。# tr -d 删除多余的引号，这个视情况而定，字符串可以不删除引号array=($(yabai -m query --displays | jq &#39;.[].index | @sh&#39; | tr -d \\&#39;\\&quot;))" }, { "title": "mpv播放器介绍", "url": "/posts/mpv%E6%92%AD%E6%94%BE%E5%99%A8%E4%BB%8B%E7%BB%8D/", "categories": "", "tags": "linux, mpv", "date": "2019-02-27 00:00:00 +0800", "snippet": "在windows下视频播放器potplayer是不二之选，可转到Linux下苦于找不到好看且功能强大的播放器，直到mpv的出现。初识一开始我使用的是VLC，虽然这是个跨平台的播放器，口碑也还不错，可在我电脑表现的却差强人意。其中有这3个主要原因使我萌生了放弃它的想法： 功能强大却界面复杂，不能及时找到要调整的选项 可能是我显卡驱动没调整好，播放过高画质的视频有卡顿 不支持多个播放列表功能！！！ （这是我放弃VLC的最重要的原因，连续几天中午看武林外传但没有记录，导致漏看和重复）所以我去寻找了其他播放器，说实话，mpv最初是无奈之选，因为Linux下其他的播放器要么很丑，要么停止更新了，所以我也只好选择最简洁的mpv简单使用这是啥？怎么啥按键没有？这咋用？估计很多人第一次使用这个播放器都会有这样的绝望三连，没错GUI下所有的设置都是和按键绑定的。别急着挠头，并不需要你记住那么多按键映射，我总结了一下，最常用的也不超过10个，在表中加粗表示： 按键 设置 z，x 字幕延后，提前 f 全屏 q，Q 退出， 记忆播放位置退出 左右 播放进度后退，前进5秒 空格或p 暂停 1，2 对比度-，+ 3，4 亮度-，+ 5，6 伽马-，+ 7，8 饱和度-，+ 9，0 音量-，+ 上，下 播放进度快进，倒退1分钟 ctrl+&amp;lt;-&amp;gt;或&amp;lt;+&amp;gt; 音轨快进，减慢 i，I 显示视频的详情参数(一直显示) m 静音 {或[， }或] 播放速度减慢，加快(倍率不同) backspace 播放速度返回到一倍速 s 截图 就用这几个键我也陆陆续续使用了一个月，可是慢慢地我也发现了局限的地方，不过通过不断的查询了解，我还是找到了一些解决方法，在下章详细介绍高级设置详细文档参见mpv wikimpv的默认配置文件存于~/.config/mpv我的file tree如下:其中scripts和script-settings是从官方脚本中扒的各个配置和脚本文件介绍 input.conf 按键配置可以参考这个配置文件 WHEEL_UP add volume 2 # 滚轮上增加2%音量 WHEEL_DOWN add volume -2 # 滚轮下减少2%音量 WHEEL_LEFT seek 10 # 滚轮左快进10秒 WHEEL_RIGHT seek -10 # 滚轮右后退10秒 UP add volume 5 DOWN add volume -5 LEFT seek -5 RIGHT seek 5 # alt加左右旋转视频，配合cycle-video-rotate.lua脚本 Alt+LEFT script-message Cycle_Video_Rotate -90 Alt+RIGHT script-message Cycle_Video_Rotate 90 # alt+9，0 快速调整窗口尺寸， 配合quick-scale.lua Alt+9 script-message Quick_Scale &quot;1920&quot; &quot;1080&quot; &quot;0.9&quot; &quot;-1&quot; Alt+0 script-message Quick_Scale &quot;1920&quot; &quot;1080&quot; &quot;0.5&quot; &quot;-1&quot; # ctrl+b触发blackbox，配合blackbox.lua ctrl+b script-binding Blackbox mpv.conf 全局配置 alang=zh，chi #指定优先使用音轨 slang=zh，chi #指定优先使用字幕轨 hwdec=auto #视频硬件解码 volume-max=200 #音量最大值设定（范围：100.0-1000.0) sub-auto=fuzzy #加载视频文件的外部字幕文件方式（fuzzy 加载含有视频文件名的全部字幕文件） screenshot-directory=~/Pictures/mpv #截屏文件保存路径 screenshot-jpeg-quality=100 #截屏jpeg 质量（0-100），默认值为90 scripts文件夹mpv启动时，保存在该目录中的脚本将被自动加载并执行，参考官方脚本 Blackbox.js这个解决了快速切换文件夹内的文件，ctrl+b触发，可在input.conf修改 recent.lua显示历史记录，这个和blackbox联合使用可以当做一个简易的播放列表，因为从播放历史播放的话会进入该视频的文件夹，所以可以用blackbox.js选择下一视频播放，配置可在recent.lua中修改，默认用`触发可以看到有多个《重版出来!》，其实他们不是同一个视频，所以可见是通过获取视频媒体信息得到标题(如果有)，有利有弊吧总结以开箱即用的易用性来评价mpv的话，毫无疑问是不及格的，没有gui配置选项，没有各种记录，播放列表，让新手没有操作手册的情况下根本无法使用!但是如果你学习一下基本操作，看看官方脚本，尝试各种命令行参数，甚至自己编写脚本，这样mpv作为一个播放器基本框架，通过你添加需要的插件逐渐丰富，变成一个不臃肿的且最适合你的播放器。我也没有深入的了解，你可以多到官方脚本库中寻找解决你痛点的脚本。" }, { "title": "Linux使用百度网盘", "url": "/posts/linux%E4%BD%BF%E7%94%A8%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98/", "categories": "", "tags": "linux", "date": "2019-02-21 00:00:00 +0800", "snippet": "在linux下很容易想到使用wine或crossover安装windows版本的百度网盘。但这样仍然会受限速的困扰。使用BaiduPCS-GO的多线程并行下载能有效提高速度，并且其类终端交互方式在linux的使用中对编写自定义脚本更为友好。 目前作者已停止更新,但仍能使用安装在其项目github release页下载设备对应平台的版本。解压到任意目录，其中dowload文件夹是下载文件夹，BaiduPCS-GO是执行程序，使用chmod +x BaiduPCS-Go为其赋权使用基本开箱即用，执行其程序。并用help命令查看指令帮助，大多和linux类似，详细介绍省略可以执行程序进入其界面,也可./BaiduPCS-GO ls带参数执行单条命令,方便编写脚本 由于该软件已被百度云记录，不能直接下载需要更改appid来获取下载权限(由于百度云保证/apps/baidu_shurufa路径,即自家百度输入法的下载权限和速率,所以可以将文件放到此目录下载)，但拥有下载权限的appid又没有根目录权限 满速权限：config set -appid=265486根目录权限：config set -appid=266719满速目录：/apps/baidu_shurufa 下载流程为: 更换为根目录权限appid 移动下载文件到/apps/baidu_shurufa 更换为下载权限appid，下载 直接编写脚本该脚本涵盖了3个我常用的功能,下载,删除,bt磁力下载 下载,是我将所有要下载的文件先转移到/我的资源文件夹,执行脚本,输入序号即可下载,下载大致流程的上述相同,下载完毕后打开所在路径的文件夹 删除,我发现不如直接使用其内置的删除命令,还能使用通配符,所以脚本的删除功能也就是切换权限并跳到/我的资源文件夹下,也可以单纯使用该命令快速换权并进入程序 bt磁力下载,可惜该软件不能显示磁力下载的进度,所以我使用watch -n来监测/我的资源文件夹下的变化,对于很快下载完的文件还好,但是对于下载失败或者磁力速度特别慢的只能去网页上看了 编写脚本后使用ln -s &amp;lt;脚本绝对路径&amp;gt; ~/.lcoal/bin/baidu-dl软链接到baidu-dl命令 下载 baidu-dl 删除 baidu-dl del bt下载 baidu-dl bt 脚本如下: #!/bin/bash SCRIPT_PATH=&quot;/home/mopip77/Desktop/BaiduPCS-Go-v3.5.6-linux-amd64&quot; # 程序路径 FILE_STORE_PATH=&quot;/我的资源/&quot; # 网盘上下载文件夹路径 TMP_LIST_FILE=&quot;/tmp/baidu_pan.tmp&quot; # 临时文件 DOWNLOAD_PATH=&quot;/home/mopip77/Desktop/BaiduPCS-Go-v3.5.6-linux-amd64/download/1131301918_Mopip77/apps/baidu_shurufa&quot; # 本机下载的位置(因为都转移到baidu_shurufa下了,所以/apps/baidu_shurufa即为本机的下载根路径) cd $SCRIPT_PATH # 切换权限账号 ./BaiduPCS-Go config set -appid=266719 if [[ $# -eq 1 &amp;amp;&amp;amp; $1 == &quot;del&quot; ]] then echo -e &quot;\\033[46;30m 使用rm命令删除文件\\033[0m:&quot; ./BaiduPCS-Go ls &quot;$FILE_STORE_PATH&quot; ./BaiduPCS-Go cd &quot;$FILE_STORE_PATH&quot; ./BaiduPCS-Go elif [[ $# -eq 1 &amp;amp;&amp;amp; $1 == &quot;bt&quot; ]] then # 磁力下载 echo -e &quot;\\033[46;30m 输入磁力链接:\\033[0m:&quot; read btLink ./BaiduPCS-Go od add -path=$FILE_STORE_PATH &quot;$btLink&quot; watch -n 3 ./BaiduPCS-Go ls &quot;$FILE_STORE_PATH&quot; else # 下载 ./BaiduPCS-Go ls &quot;$FILE_STORE_PATH&quot; &amp;gt; $TMP_LIST_FILE ./BaiduPCS-Go ls &quot;$FILE_STORE_PATH&quot; echo -e &quot;\\033[46;30m 输入文件(夹)编号下载: \\033[0m&quot; read dlCodes # 记录所有下载文件的名字 index=0 dlFileNames=() for i in ${dlCodes[*]} do # 前五行无用, 也不用sed删了, 直接加一下吧 let num=i+5 dlFileNames[$index]=$(cat $TMP_LIST_FILE | awk &#39;NR==&quot;&#39;$num&#39;&quot;{print $5}&#39;) let index=index+1 done # 转移所有下载文件 ./BaiduPCS-Go cd $FILE_STORE_PATH ./BaiduPCS-Go cp ${dlFileNames[*]} /apps/baidu_shurufa # 下载所有文件 ./BaiduPCS-Go cd /apps/baidu_shurufa/ ./BaiduPCS-Go config set -appid=265486 ./BaiduPCS-Go d ${dlFileNames[*]} # 删除要下载的文件(/app/baidu_shurufa文件夹下的) ./BaiduPCS-Go rm ${dlFileNames[*]} exo-open --launch FileManager $DOWNLOAD_PATH fi " }, { "title": "Ffmpeg常见用法【持续更新】", "url": "/posts/ffmpeg%E5%B8%B8%E8%A7%81%E7%94%A8%E6%B3%95-%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/", "categories": "", "tags": "ffmeg, video", "date": "2019-01-23 00:00:00 +0800", "snippet": "由于ffmpeg对我来说不常用,所以基本每次用都得百度一会,而且好用的命令并不多,所以记录一下我用过的命令。 截取mp4ffmpeg -ss 1:18 -t 4:07 -accurate_seek -i input.mp4 -codec copy -avoid_negative_ts 1 out.mp4其中, -ss 1:18 -t 4:07 表示从从视频的第1:18开始截取4:07的视频 提取音频ffmpeg -i input.mp4 -vn -y -acodec copy bt.aac 合并mp4 #转成ts后拼接ffmpeg -i 1.mp4 -vcodec copy -acodec copy -vbsf h264_mp4toannexb 1.tsffmpeg -i 2.mp4 -vcodec copy -acodec copy -vbsf h264_mp4toannexb 2.tsffmpeg -i &quot;concat:1.ts|2.ts&quot; -acodec copy -vcodec copy -absf aac_adtstoasc output.mp4 MP4 -&amp;gt; GIFffmpeg -ss 2 -t 10 -i out.ogv -s 649x320 -r 15 out.gif 其中, -ss 2 -t 12 表示从从视频的第2秒开始转换, 转换时间长度为10秒. -s用于设定大小, -r 用于设定帧数. 使用默认的ffmpeg转换后的gif图片像素会有抖动，因此需要使用滤镜: #!/bin/shpalette=&quot;/tmp/palette.png&quot;filters=&quot;fps=15,scale=320:-1:flags=lanczos&quot;ffmpeg -v warning -i $1 -vf &quot;$filters,palettegen&quot; -y $paletteffmpeg -v warning -i $1 -i $palette -lavfi &quot;$filters [x]; [x][1:v] paletteuse&quot; -y $2 将上述命令保存为a.sh，使用./a.sh input.mp4 out.gif生成更清楚的gif图像，其中scale用来调整尺寸，可自行更改 单张图片和一段音频合成视频ffmpeg -r 1 -f image2 -loop 1 -i in.jpg -i in.aac -s 1920x1200 -pix_fmt yuvj420p -t 336 -vcodec mpeg4 out.mp4 -r 是帧数，因为只有一张图片所以设置为1，我原本用的是15，成品画质极差而且转码时间很长。-loop 由于只有一张图片，循环-s 分辨率，可随意设置，最好和图片等比-t 视频时长 单位秒，必须和音频等长，若短则后面被剪切。若长还不是后面没声音，而是音轨出现漂移时有时无 音视频合并分两种情况, 命令不相同 原视频没有音频ffmpeg -i video.mp4 -i audio.wav -c:v copy -c:a aac -strict experimental output.mp4 原视频有音频，使用新的音频替换视频中的音频ffmpeg -i video.mp4 -i audio.wav -c:v copy -c:a aac -strict experimental -map 0:v:0 -map 1:a:0 output.mp4 " }, { "title": "Ahk使用教程", "url": "/posts/Ahk%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/", "categories": "", "tags": "", "date": "2019-01-17 00:00:00 +0800", "snippet": "ahk是一个键盘脚本软件(语言)，使用好他能极大提高重复工作的效率AutoHotKey Windows下使用待更新AutoKey Linux下使用AutoKey 可以理解为Linux下的AutoHotKey的替代品，但相较于AutoHotKey需要学习一种新的语言而言，Autokey使用Python编写，其脚本语言也是Python，对于接触过Python的用户来说，该软件上手是毫无难度的。安装对于Ubuntu/mint用户,使用sudo apt install autokey-gtk安装界面介绍左边是代码文件夹，除文件夹外只有两种格式的文件，短语和脚本。可见和AutoHotKey不同，这里每个代码文件只能执行一种功能，所以需要你合理使用文件夹和命名。右边是文件夹设置，包括了Abbreviations，HotKey，Window Filter。分别是缩写触发，快捷键触发，特定窗口触发。设置文件夹的触发功能控制整个文件夹内代码是否被启用。其中每个代码文件也有单独的这三项设置。 文本替换在文件夹下新建一个Pharse，在右边框内输入你要替换的文本 缩写触发 如上图，首先Add一个缩略短语，然后在右边详细设置，通常只需要将前两项打钩，分别是移除缩略短语，忽略触发键。其余设置可自行尝试。 Trigger on， 有三种触发模式，在输入完缩略短语后，任意键触发，空格回车触发，tab触发 快捷键触发 可直接点击Press to Set来设置 特定窗口设置通过设置此项来控制触发的环境，即某一特定窗口打开时(不管是否是活动窗口)脚本才能触发。点击Detect Win…，然后点击要触发的窗口，图中我点击了Autokey窗口，然后选择是窗口类(整个应用)还是窗口标题。 脚本文件相信使用linux的同学对编程或多或少有些了解，给出官方API可自行研究。下面给出基本的语句 # 发送单键akeyboard.send_key(&quot;a&quot;)# 发送多键，alt + enter键keyboard.send_keys(&quot;&amp;lt;alt&amp;gt;+&amp;lt;enter&amp;gt;&quot;)# 发送短语keyboard.send_keys(&quot;hello&quot;) 特殊按键需要用&amp;lt;key&amp;gt;形式表示，以下是特殊按键列表 循环 import timefor i in range(0, 3):keyboard.send_keys(&quot;hello&quot;)time.sleep(0.05)keyboard.send_keys(&quot;&amp;lt;enter&amp;gt;&quot;) 判断活动窗口因为自带的窗口选择器只能判断一种窗口，所以可以在代码中识别多个窗口 winClass = window.get_active_class()if winClass == &#39;xfce4-terminal.Xfce4-terminal&#39; or winClass == &#39;tilix.Tilix&#39;: keyboard.send_keys(&quot;&amp;lt;ctrl&amp;gt;+&amp;lt;page_up&amp;gt;&quot;)else: keyboard.send_keys(&quot;&amp;lt;ctrl&amp;gt;+&amp;lt;tab&amp;gt;&quot;) 再往下扩展无非是python代码和其API的使用的增加，可以自行尝试 说说Autokey的缺点: python编写，响应速度慢 在一些软件中很不好用，例如vscode，由于我大多使用alt的快捷键，在vscode中会触发菜单，导致无法使用 自带代码窗口不可调大字体别忘了在菜单的首选项中把开机自启勾上" }, { "title": "Aria2+OneDrive VPS自动下载上传到网盘 简易版", "url": "/posts/Aria2+Onedrive%E7%AE%80%E6%98%93%E7%89%88/", "categories": "", "tags": "aria2, linux, onedrive, rclone", "date": "2018-11-30 00:00:00 +0800", "snippet": " 由于之前的教程需要安装lnmp需要花费大量时间，所以找到了一种更为简易的方式 但是本方法需要本地和远端配合，所以需要本地有一个linux环境，windows下可以用linux子系统安装配置aria2 在服务器都安装aira wget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/aria2.sh &amp;amp;&amp;amp; chmod +x aria2.sh &amp;amp;&amp;amp; bash aria2.sh#选1安装，安装完成后记录默认的随机密码，也可在脚本中修改密码 修改服务器aria配置 # 新建下载文件夹mkdir -p /data/Download#进入Aria2的目录，默认在~/.aria2#修改aria2.conf中的下载目录dir=/data/aria2/Download#并在配置文件末尾添加下面一行，即下载完成执行脚本on-download-complete=/root/.aria2/upload2one.sh 修改完了得重启一下aria服务使其生效/etc/init.d/aria2 restart 安装AriaNg 由于是简易版安装，所以不在服务器上配置域名、安装AriaNg，直接通过本地AriaNg程序访问在 https://github.com/mayswind/AriaNg/releases 中找到最新的AllInOne包下载解压后是一个html文件，直接用浏览器打开即可用浏览器打开后，此时显示未连接，选择左侧的AriaNg设置。选择RPC后，将刚刚记录的Aria2密码填入红色箭头框中并且将RPC地址改成你的服务器IP再点击弹出来的重新加载页面，状态变成已连接。安装rclone rclone是一个命令行的网盘同步工具在服务器和本地都安装wget https://rclone.org/install.shbash install.sh将onedrive信息加入到rclone# 进入rclone配置➜ rclone config2018/11/30 21:53:03 NOTICE: Config file &quot;/root/.config/rclone/rclone.conf&quot; not found - using defaultsNo remotes found - make a new onen) New remotes) Set configuration passwordq) Quit confign/s/q&amp;gt; nname&amp;gt; one # 随意起一个名字Type of storage to configure.Enter a string value. Press Enter for the default (&quot;&quot;).Choose a number from below, or type in your own value 1 / A stackable unification remote, which can appear to merge the contents of several remotes \\ &quot;union&quot; 2 / Alias for a existing remote \\ &quot;alias&quot; 3 / Amazon Drive \\ &quot;amazon cloud drive&quot; 4 / Amazon S3 Compliant Storage Providers (AWS, Ceph, Dreamhost, IBM COS, Minio) \\ &quot;s3&quot; 5 / Backblaze B2 \\ &quot;b2&quot; 6 / Box \\ &quot;box&quot; 7 / Cache a remote \\ &quot;cache&quot; 8 / Dropbox \\ &quot;dropbox&quot; 9 / Encrypt/Decrypt a remote \\ &quot;crypt&quot;10 / FTP Connection \\ &quot;ftp&quot;11 / Google Cloud Storage (this is not Google Drive) \\ &quot;google cloud storage&quot;12 / Google Drive \\ &quot;drive&quot;13 / Hubic \\ &quot;hubic&quot;14 / JottaCloud \\ &quot;jottacloud&quot;15 / Local Disk \\ &quot;local&quot;16 / Mega \\ &quot;mega&quot;17 / Microsoft Azure Blob Storage \\ &quot;azureblob&quot;18 / Microsoft OneDrive \\ &quot;onedrive&quot;19 / OpenDrive \\ &quot;opendrive&quot;20 / Openstack Swift (Rackspace Cloud Files, Memset Memstore, OVH) \\ &quot;swift&quot;21 / Pcloud \\ &quot;pcloud&quot;22 / QingCloud Object Storage \\ &quot;qingstor&quot;23 / SSH/SFTP Connection \\ &quot;sftp&quot;24 / Webdav \\ &quot;webdav&quot;25 / Yandex Disk \\ &quot;yandex&quot;26 / http Connection \\ &quot;http&quot;Storage&amp;gt; 18 # 选择Onedrive，编号可能不同** See help for onedrive backend at: https://rclone.org/onedrive/ **Microsoft App Client IdLeave blank normally.Enter a string value. Press Enter for the default (&quot;&quot;).client_id&amp;gt; # 留空Microsoft App Client SecretLeave blank normally.Enter a string value. Press Enter for the default (&quot;&quot;).client_secret&amp;gt; # 留空Edit advanced config? (y/n)y) Yesn) Noy/n&amp;gt; nRemote configUse auto config? * Say Y if not sure * Say N if you are working on a remote or headless machiney) Yesn) Noy/n&amp;gt; nFor this to work, you will need rclone available on a machine that has a web browser available.Execute the following on your machine: rclone authorize &quot;onedrive&quot;Then paste the result below:result&amp;gt; 在这一步需要授权OneDrive，需要在本机上执行rclone authorize &quot;onedrive&quot;，在 http://127.0.0.1:53682/auth 上登录你的OneDrive登录成功后会返回类似这样的信息将返回的内容和大括号一起复制到服务器# 服务器后续Choose a number from below, or type in an existing value 1 / OneDrive Personal or Business \\ &quot;onedrive&quot; 2 / Root Sharepoint site \\ &quot;sharepoint&quot; 3 / Type in driveID \\ &quot;driveid&quot; 4 / Type in SiteID \\ &quot;siteid&quot; 5 / Search a Sharepoint site \\ &quot;search&quot;Your choice&amp;gt; 1Found 1 drives, please select the one you want to use:0: (personal) id=6eb85ea240738233Chose drive to use:&amp;gt; 0Found drive &#39;root&#39; of type &#39;personal&#39;, URL: https://onedrive.live.com/?cid=6eb85ea240738233Is that okay?y) Yesn) Noy/n&amp;gt; y --------------------[one]type = onedrivetoken = {&quot;access_token&quot;:}drive_id = 6eb85ea240738233drive_type = personal--------------------y) Yes this is OKe) Edit this remoted) Delete this remotey/e/d&amp;gt; yCurrent remotes:Name Type==== ====one onedrivee) Edit existing remoten) New remoted) Delete remoter) Rename remotec) Copy remotes) Set configuration passwordq) Quit confige/n/d/r/c/s/q&amp;gt; q编写上传脚本vi ~/.aria2/upload2one.sh,将如下内容添加到该脚本中，并且将downloadpath，name，folder字段替换成你的信息#!/bin/bashfilepath=$3 #取文件原始路径，如果是单文件则为/Download/a.mp4，如果是文件夹则该值为文件夹内第一个文件比如/Download/a/1.mp4path=${3%/*} #取文件根路径，如把/Download/a/1.mp4变成/Download/adownloadpath=&#39;/data/Download&#39; #Aria2下载目录name=&#39;one&#39; #配置Rclone时的namefolder=&#39;/share&#39; #网盘里的文件夹，如果是根目录直接留空MinSize=&#39;10k&#39; #限制最低上传大小，默认10k，BT下载时可防止上传其他无用文件。会删除文件，谨慎设置。MaxSize=&#39;15G&#39; #限制最高文件大小，默认15G，OneDrive上传限制。if [ $2 -eq 0 ]; then exit 0; fiwhile true; doif [ &quot;$path&quot; = &quot;$downloadpath&quot; ] &amp;amp;&amp;amp; [ $2 -eq 1 ] #如果下载的是单个文件 then rclone move -v &quot;$filepath&quot; ${name}:${folder} --min-size $MinSize --max-size $MaxSize rm -vf &quot;$filepath&quot;.aria2 #删除残留的.aria.2文件 rm &quot;$filepath&quot; exit 0elif [ &quot;$path&quot; != &quot;$downloadpath&quot; ] #如果下载的是文件夹 then while [[ &quot;`ls -A &quot;$path/&quot;`&quot; != &quot;&quot; ]]; do rclone move -v &quot;$path&quot; ${name}:/${folder}/&quot;${path##*/}&quot; --min-size $MinSize --max-size $MaxSize --delete-empty-src-dirs rclone delete -v &quot;$path&quot; --max-size $MinSize #删除多余的文件 rclone rmdirs -v &quot;$downloadpath&quot; --leave-root #删除空目录，--delete-empty-src-dirs 参数已实现，加上无所谓。 done rm -vf &quot;$path&quot;.aria2 #删除残留的.aria2文件 rm -rf &quot;$path&quot; exit 0fidone最后给脚本权限chmod +x ~/.aria2/upload2one.sh最后可以下载一个东西试试了～ 由于上传方式不同所以比之前的方法会慢一点，如果在意上传的速度，还是使用之前的方法吧" }, { "title": "Linux软件", "url": "/posts/Linux%E8%BD%AF%E4%BB%B6/", "categories": "", "tags": "linux", "date": "2018-11-27 00:00:00 +0800", "snippet": "由于最近转到了linuxmint，找到了一些优秀的软件视频图片 obs 安装教程 flameshot linux下代替Snipaste的截图工具，可以截图后直接编辑，但可惜没有贴图功能 apt安装，可以绑定快捷键，命令是flameshot gui vlc编程工具 pycharm idea vscode sublime 因为在linux下vscode挺快的，所以没安装 guake terminal FileZilla sftp工具文档编辑 wps 可能会出现字体安装不全，百度一下很容易解决 typora 安装教程其他工具 Clipit 剪贴板历史，代替ditto，但可惜只能记录文字，而且还不能翻页！！ 但聊胜于无吧 Autokey 自动按键脚本，代替AutoHotKey，执行的是python脚本，对于用过python的用户它很容易上手，不过毕竟是python脚本有时候可能反应有点慢，尤其是在vscode下，很容易不触发 qBittorrent uGet 坚果云 安装教程 登陆的时候可能会出现ssl连接失败 备份并移除老的cacerts sudo mv /etc/ssl/certs/java/cacerts{,.backup} 生成新的cacerts sudo keytool -importkeystore -destkeystore /etc/ssl/certs/java/cacerts -deststoretype jks -deststorepass changeit -srckeystore /etc/ssl/certs/java/cacerts.backup -srcstoretype pkcs12 -srcstorepass changeit tlp 笔记本省电管理主题美化 xfce在 xfce-look 有很多主题这个见仁见智，我在xfce桌面下是这样设置的 窗口管理器样式 X-Arc-White 外观样式 X-Arc-Plus 图标 Flat Remix这个图标还是不错的，各种类型文件都包含了，如上图 cinnamon(主要使用)发现cinnamon其实在笔记本续航上没比xfce短多少, 动效和观感比xfce好挺多，皮肤也能去上面的网站使用gtk3的皮肤主题如下， 自己搜索" }, { "title": "Linux插件", "url": "/posts/linux%E6%8F%92%E4%BB%B6/", "categories": "", "tags": "linux", "date": "2018-11-13 00:00:00 +0800", "snippet": "linux下必备插件Terminalzsh &amp;amp; oh-my-zsh 安装zsh sudo apt-get install zsh # 把默认的Shell改成zsh, 注意：不要使用sudo chsh -s /bin/zsh #配置密码文件，解决chsh: PAM认证失败的问题 sudo vim /etc/passwd #把第一行的/bin/bash改成/bin/zsh，这个是root用户的。 #同理,如果你使用非root账户则将文件中对应用户进行相同更改 安装oh-my-zsh # 两种安装方式curl或者wget,二者选其一 sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; sh -c &quot;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; 更改omz主题 #在该网站选择主题,复制其名字 sudo vim ~/.zshrc #找到ZSH_THEME这一项,后面改成主题名 #生效 source ~/.zshrc 建议改成agnoster,效果如下 注意: 如果使用该主题时,箭头出现乱码,可考虑使用powerline字体 git clone https://github.com/powerline/fonts.git cd fonts ./install.sh 找到新欢主题af-magic，可是自带提示符是#,如下操作更改符号 vi ~/.oh-my-zsh/themes/af-magic.zsh-theme #找到(!.#.»)，改成 (!.».») #再source使其生效 再次找到主题ys，修改成如下配色。箭头不是默认的，可到默认主题中复制过来。 autojump自动跳转插件 安装 sudo apt-get install autojump 配置 vim .zshrc #在最后一行加入，注意点后面是一个空格 . /usr/share/autojump/autojump.sh 生效 source ~/.zshrc zsh-syntax-highlighting语法高亮 安装 #此仓库不能删，建议安装在 ~/.oh-my-zsh/custom/plugins/ git clone https://github.com/zsh-users/zsh-syntax-highlighting.git #在安装路径下执行 echo &quot;source ${(q-)PWD}/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh&quot; &amp;gt;&amp;gt; ${ZDOTDIR:-$HOME}/.zshrc 生效 source ~/.zshrc extract不带参数快速解压，直接在.zshrc的plugins中添加即可。tree (apt安装)tmux (apt安装)zsh-autosuggestions 提示历史输入，安装教程Vimpathogen.vim vim插件管理系统 安装 mkdir -p ~/.vim/autoload ~/.vim/bundle &amp;amp;&amp;amp; \\ curl -LSso ~/.vim/autoload/pathogen.vim https://tpo.pe/pathogen.vim #If you&#39;re using Windows, change all occurrences of ~/.vim to ~\\vimfiles 添加配置 添加以下到~/.vimrc execute pathogen#infect() syntax on filetype plugin indent on nerdtree 树形文件管理 安装 git clone https://github.com/scrooloose/nerdtree.git ~/.vim/bundle/nerdtree 配置快捷键和启动项 如果要每次启动vim出现，将其加入你的~/.vimrc autocmd StdinReadPre * let s:std_in=1 autocmd VimEnter * if argc() == 0 &amp;amp;&amp;amp; !exists(&quot;s:std_in&quot;) | NERDTree | endif 设置快捷键，将其加入你的~/.vimrc #ctrl-n map &amp;lt;C-n&amp;gt; :NERDTreeToggle&amp;lt;CR&amp;gt; " }, { "title": "Linux下安装ffmpeg", "url": "/posts/Linux%E4%B8%8B%E5%AE%89%E8%A3%85ffmpeg/", "categories": "", "tags": "ffmpeg, linux", "date": "2018-11-02 00:00:00 +0800", "snippet": "1. 下载ffmpegwget https://ffmpeg.org/releases/ffmpeg-4.0.2.tar.bz2tar -xjvf ffmpeg-4.0.2.tar.bz2cd ffmpeg-4.0.22. 安装yasmyasm是一款汇编器，并且是完全重写了nasm的汇编环境，接收nasm和gas语法，支持x86和amd64指令集，所以这里安装一下yasm即可。tar -xvzf yasm-1.3.0.tar.gzcd yasm-1.3.0/./configuremakemake install3. 安装ffmpeg#回到ffmpeg的文件夹./configure --enable-shared --prefix=/app/ffmpegmakemake install编译过程有点长，耐心等待完成之后执行 cd /app/ffmpeg/ 进入安装目录，查看一下发现有bin,include,lib,share这4个目录，其中bin是ffmpeg主程序二进制目录，include是C/C++头文件目录，lib是编译好的库文件目录，share是文档目录。4. 配置ffmpeg 将库文件导入linuxvi /etc/ld.so.conf.d/ffmpeg.conf#加入下面这行/app/ffmpeg/lib#保存退出后，执行下面，使其生效ldconfig 将路径添加进变量vi /etc/profile#到最后一行export PATH=/app/ffmpeg/bin:$PATH#保存退出后，执行下面，使其生效source /etc/profile" }, { "title": "Aria2+OneDrive VPS自动下载上传到网盘", "url": "/posts/Aria2+OneDrive-VPS%E8%87%AA%E5%8A%A8%E4%B8%8B%E8%BD%BD%E4%B8%8A%E4%BC%A0%E5%88%B0%E7%BD%91%E7%9B%98/", "categories": "", "tags": "aria2, linux, onedrive", "date": "2018-09-24 00:00:00 +0800", "snippet": " 本教程基于Debian8安装lnmpapt-get update#需要组件如下，可用apt-get install 安装curl git unzip wget screen python(自带2.7就行)#install lnmpwget http://mirrors.linuxeye.com/lnmp-full.tar.gztar xzf lnmp-full.tar.gzcd lnmp./install.sh #此过程很长需要15min左右安装选项——仅列出所有需要选y的项，其余选n或默认install Web server [y]install Database [y]install PHP [y]install phpMyAdmin [y]安装完毕后，提示是否重启VPS，选y重启。绑定域名需要两个域名。一个用于下载，一个用于操作网盘。本教程使用两个二级域名dl2.mydomain 以及 pan2.mydomain，用A记录指向自己的服务器IP。#进入lnmp文件夹./vhost.sh选 3. Use Let&#39;s Encrypt to Create SSL Certificate and Key再输入上方的创建域名其余全选n，再重复一次输入另一个域名安装Aria2wget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/aria2.sh &amp;amp;&amp;amp; chmod +x aria2.sh &amp;amp;&amp;amp; bash aria2.sh#选1安装，安装完成后记录默认的随机密码，也可在脚本中修改密码下载AriaNg和OneIndex源码AriaNg是aira2的一个网页模板#进入你所定义的下载域名文件夹cd /data/wwwroot/dl2.mydomainwget https://github.com/mayswind/AriaNg/releases/download/0.5.0/AriaNg-0.5.0.zipunzip AriaNg-0.5.0.ziprm AriaNg-0.5.0.zipOneIndex是OneDrive的网页模板#进入你所定义的网盘域名文件夹cd /data/wwwroot/pan2.mydomaingit clone https://github.com/donwa/oneindex .配置AriaNg和OneIndexAriaNg用浏览器打开dl2.mydomain，此时显示未连接，选择左侧的AriaNg设置。选择RPC后，将刚刚记录的Aria2密码填入红色箭头框中，再点击弹出来的重新加载页面，状态变成已连接。Aria2#进入Aria2的目录，默认在~/.aria2#修改aria2.conf中的下载目录dir=/data/aria2/Download#并在配置文件末尾添加下面一行，即下载完成执行脚本on-download-complete=/root/.aria2/upload2one.sh编写 upload2one.sh#!/bin/bashpath=$3downloadpath=&#39;/data/aria2/Download&#39; #这里改成你定义的下载文件夹if [ $2 -eq 0 ] then exit 0fiwhile true; dofilepath=$pathpath=${path%/*};if [ &quot;$path&quot; = &quot;$downloadpath&quot; ] &amp;amp;&amp;amp; [ $2 -eq 1 ] #上传文件 then /usr/local/php/bin/php /data/wwwroot/pan2.mydomain/one.php upload:file &quot;$filepath&quot; /uploadfolder/ rm -rf &quot;$filepath&quot; #mydomain 改成自己的域名 exit 0elif [ &quot;$path&quot; = &quot;$downloadpath&quot; ] #上传文件夹 then /usr/local/php/bin/php /data/wwwroot/pan2.mydomain/one.php upload:folder &quot;$filepath&quot;/ /uploadfolder/&quot;${filepath##*/}&quot;/ #mydomain 改成自己的域名 rm -rf &quot;$filepath&quot;/ exit 0fidone给该脚本权限chmod +x /root/.aria2/upload2one.sh重启Aria2服务/etc/init.d/aria2 restart**Notice: **两行pan2.mydomain改成自己网盘域名，后面跟着的uploadfolder是远程网盘中的根目录下的指定文件夹，可以改成自己喜欢的。两行rm删除指令会在上传完成后删除下载的文件，在VPS容量有限时用。并且在传超过2G以上文件时上传可能失败，而删除指令仍会执行，建议注释掉。OneIndex给www读写权限chown -R www:www /data/wwwroot浏览器打开pan2.mydomain这里需要OneDrive的授权，点击蓝色框登陆将密钥复制到clinet sccret后，点击知道了，返回到快速启动将APP ID复制过去提示 默认的Aria2设置中，bt下载完成后会在正在下载队列里保种，即不会完成下载而且一直上传。如果使用限定流量的VPS建议如下操作。最小分享率改成1.0。如果实在不想保种可将最小做种时间改成0，即下完立刻完成。两个上传脚本you-get下载后上传，具体规范看脚本#!/bin/bash# 基于oneindex + you-get# 新建opt文件夹 并且保持里面是空的# 视频链接必须每行一条 保存在当前路径v.txt下# 由于下完即删不保证上传，所以v.txt的内容不动，根据实际情况移除以下载的链接opt=&quot;/root/videos&quot;video=( $(cat v.txt) )count=0# 如果有重名的下载文件，用count计数并添加在文件名前，以防重名， same_name 0,1表示是否会重名same_name=0# 删除没用的文件，字幕文件，弹幕文件del_useless_file() { rm ${opt}/*.srt rm ${opt}/*.xml}for i in ${video[@]}do let &quot;count=$count+1&quot; # 默认用137 即 1080p MP4 下载，下不了则用默认下载 you-get --itag=137 -o ${opt} ${i} del_useless_file fp=$(ls $opt) if [ ! $fp ];then # 由于采用最简单的ls 来获取下载的视频，必须保证文件夹内只有一个文件 # youtube 1080p 视频音频分开 必须安装ffmpeg才能自动合成 you-get -o $opt ${i} del_useless_file fp=$(ls $opt) fi if [ $same_name -eq 1 ] then # mydomain 改成自己的域名 php /data/wwwroot/pan2.mydomain/one.php upload:file &quot;$opt/$fp&quot; &quot;/upload/${count}${fp}&quot; else # mydomain 改成自己的域名 php /data/wwwroot/pan2.mydomain/one.php upload:file &quot;$opt/$fp&quot; &quot;/upload/${fp}&quot; fi rm &quot;$opt/$fp&quot; echo &quot;[*]\\n第$count 个视频完成操作（不保证上传完成）\\n&quot;done这里如果使用screen来下载并检查是否下载成功，可能会无法用滚轮翻屏。vi ~/.screenrc ，添加termcapinfo xterm* ti@:te@，这样在screen中就可用滚轮翻屏。用oneup &amp;lt;filename&amp;gt;命令上传脚本#!/bin/bashoneup() {uploadFile=$1if [ -d &quot;$uploadFile&quot; ]# mydomain 改成自己的域名then php /data/wwwroot/pan2.mydomain/one.php upload:folder &quot;$uploadFile&quot; /upload/elif [ -f &quot;$uploadFile&quot; ]# mydomain 改成自己的域名then php /data/wwwroot/pan2.mydomain/one.php upload:file &quot;$uploadFile&quot; /upload/fi}" }, { "title": "安装hexo博客作为github的个人主页", "url": "/posts/%E5%AE%89%E8%A3%85hexo%E5%8D%9A%E5%AE%A2%E4%BD%9C%E4%B8%BAgithub%E7%9A%84%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/", "categories": "", "tags": "github, hexo", "date": "2018-08-19 00:00:00 +0800", "snippet": "安装hexo安装依赖环境 git nodejs安装hexonpm install hexo-cli -g#blog 是一个未创建的博客根目录hexo init blogcd blognpm install#这是用于部署到github上的插件npm install hexo-deployer-git --save注册并配置github1.新建项目注册完github账号以后新建一个和你自己用户名(例如tom)相同前缀的仓库(tom.github.io)2.创建RSA密钥# 配置本地git #yourname, youremail替换成自己的git config --global user.name yournamegit config --global user.email youremail#生成密钥 youremail使用上一步配置的ssh-keygen -t rsa -C youremail#在~/.ssh/下找到后缀为pub的文件，复制其内容#在github的设置界面中找到ssh keys将复制的密钥粘贴进去编写配置文件#在 _config.yml的最后复制以下内容并替换原有的deploy开始到最后的内容#其中repo需要替换成你自己github个人主页的ssh链接deploy: type: git repo: git@github.com:rivaen/rivaen.github.io.git branch: master选择并配置好看的hexo皮肤我这个主题是Archer,请按照其文档配置hexo命令hexo g #生成网页模板到根目录下的publichexo s [-p port]#在本地的port端口开启hexo服务，默认4000端口hexo d #通过配置文件的git地址部署到该git地址" }, { "title": "Chrome必备插件", "url": "/posts/Chrome-plugin/", "categories": "", "tags": "Chrome, win10", "date": "2018-08-17 00:00:00 +0800", "snippet": "尝试过一些比较好用的Chrome插件 Adblock Plus 屏蔽网页上及视频的广告2. crxMouse 鼠标手势，让浏览更加便利 SmartUp 由于crxMouse似乎会上传使用数据，所以我找到了个类似的，而且功能更加完善 octTree github下左侧弹出一个树结构栏 划词翻译 不解释 简悦 沉浸式阅读 SwitchOmega 更改Chrome下代理模式，可新建不同情景模式，添加白黑名单，pac模式 OneTab 一键将所有标签页保存下来，适合用于睡觉前保存下来，明天继续工作 远方 扩展的新标签页，十分简洁，只有一张精美图片和时钟天气 快捷方式管理 当扩展程序多了以后管理不便，一键管理 慧慧购物助手 在电商网站商品详情页有价格走势，但平常可能会弹窗，建议使用时打开 网页截图 可以整页截图 Tampermonkey 油猴——脚本管理器，神器不解释，获取脚本可到Greasy Fork 查找 微博浮图 (微博等主流网站预览大图) searchEngineJump (将内容在各大网站跳转搜索) Super_preloadplus_one (百度预加载一拉到底) 视频站启用html5播放器 百度网盘直接下载助手 直链加速版 SearchBy Image 右键在新标签中打开图片时显示最优化图像质量 全网音乐一键免费下载 stylish 网页修饰插件管理器。这原本是一个chrome插件，由于涉及记录用户隐私而被下架，但其中的插件均可通过油猴安装 百度多栏 以多栏的方式浏览百度 全局思源黑体 将可以修改的css全改成思源黑体，在低分屏的win下非常有用 YouTube-Nyan Cat 替换YouTube进度条 百度Lite 以material design的方式渲染百度 " }, { "title": "git-commond", "url": "/posts/git-commond/", "categories": "", "tags": "linux, git", "date": "2018-08-09 00:00:00 +0800", "snippet": "初始化仓库#进入要做成git仓库的文件夹git init#这一步初始化git仓库，并生成一个.git的隐藏文件夹各种状态 untracked，未被仓库收纳 unmodfied，被仓库收纳，提交以后未作修改 modified， 被仓库收纳，与上一次提交修改过的 staged， 被仓库收纳add后准备提交简单流程#创建一个文件，例如a.py# 1. 将其添加到仓库git add a.pygit add . (添加文件下所有文件)# 2. 提交 message 可替换成对该次提交的描述git commit -m &quot;message&quot;# 3. add并commit# 这会提交所有“已经处于仓库”的文件，新文件不会被提交git coomit -am &quot;message&quot;# 4. 当前所有修改和上个版本的区别git diff# 5. 将这次提交归并到上一次git commit --amend [--no-edit](不修改上一次的评论)仓库状态git status [-s](单行输出)#从该版本到最初版本的信息git log [--oneline](单行) [--graph](图形，用于分支)#所有版本变化的信息git reflog 版本回滚git reset --hard HEAD^^^^# ^ 的数量代表回滚的版本次数，1个回滚1个版本git reset --hard 版本号版本号可由git refloggit log –oneline 查看单个文件回滚git checkout 版本号 -- filename# --后面有空格#若再次修改后提交不会影响到之前任何版本的记录分支#查看所有分支git branch #新建分支, branchnamegit branch branchname#分支跳转git checkout branchname#新建分支并跳转git checkout -b branchname#删除分支git branch -d branchname#将分支归并到主线，此操作必须将分支转到主线git merge --no-ff -m &quot;message&quot; branchname分支冲突：#正常情况下，主分支在分出新分支后不变，新分支更改后可以线性归并到主分支#若分出新分支后，主分支也有改变，则归并时会报错，会指出有冲突的文件，所以需要在文件中做出修改#修改完成以后再次提交，此时完成归并暂存当不想提交且需要更改之前版本代码时可将当前状态暂时保存下来#暂存git stash#弹出上次暂存git stash poppretty git-log 好看的git log显示在~目录下执行vi .gitconfig找到alias 添加dog = log --graph --pretty=format:&#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C blue&amp;lt;%an&amp;gt;%Creset&#39; --abbrev-commit --date=relative --all这样使用git dog就能更好的显示log主要命令" }, { "title": "安装MongoDB", "url": "/posts/%E5%AE%89%E8%A3%85MongoDB/", "categories": "", "tags": "linux, MongoDB", "date": "2018-07-20 00:00:00 +0800", "snippet": "安装配置MongoDB安装debian环境下参考 https://docs.mongodb.com/manual/tutorial/install-mongodb-on-debian/ ,其他版本在边栏转换 导入公钥 sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 9DA31620334BD75D9DCB49F368818C72E52529D4 建立清单文件 #该指令适用于debian8.xecho &quot;deb http://repo.mongodb.org/apt/debian jessie/mongodb-org/4.0 main&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list apt安装 sudo apt-get update#这是下载最新版，下载指定版本请参照官网sudo apt-get install -y mongodb-org 添加路径 #我没有添加好像也没啥问题，如找不到指令请添加一下#eplace &amp;lt;mongodb-install-directory&amp;gt; with the path to the extracted MongoDB archive.export PATH=&amp;lt;mongodb-install-directory&amp;gt;/bin:$PATH 配置 修改配置文件 vi /etc/mongodb.conf –默认配置文件，也可指定配置文件storage: dbPath: /data/mongodb/data/db #n你的数据库目录 需要自己建 journal: enabled: true processManagement: fork: true # fork and run in backgroundnet: port: 27017 bindIp: 0.0.0.0 #接受所有ip的访问，若只在本地运行，改成127.0.0.1 security: authorization: disabled 测试 #开启mongod数据库服务mongod -f /etc/mongodb.conf#进入mongodb,若配置中更改了端口需要添加端口信息mongo [--port=9000]#用一些数据库指令测试一下show dbsshow collections 添加账号mongo 默认谁都可以访问修改，建立多个账号并分配权限```bash#进入mongomongo#建立root(权限最高)账号use admindb.createUser({user:’root’,pwd:’xxxx’,roles:[‘root’]})#建立普通数据库访问账户use #read只读，readWrite可读可写，其他权限查百度db.createUser({user:&#39;xxxx&#39;,pwd:&#39;xxxx&#39;,roles:[&#39;read&#39;]})4. 设置访问权限 设置完账号还不行，需要更改配置文件 ```bash#修改自己的配置文件vim /etc/mongodb.confauthorization: enabled #将disabled改成enabled运行mongodb 启动启动Mongodb有两种方式```bash#1.作为服务启动service mongod start#但是这种读取默认配置，所以更改过配置文件以后不能很好地启动#2.带参数启动#若是在conf文件中指定过的指令就不需要添加mongod -f /etc/mongod.conf [–fork=true] [–port=xxxx]* 开机启动参考之前写的开机启动教程，编写脚本，加入rc.local即可### 连接数据库1. Robo软件连接* Connection填写服务器ip和端口* Authentication中 Database - 登录账号对应的数据库名* 填写账号密码登陆2. Python登陆```pythonfrom pymongo import MongoClient#username, pwd, ip, dbname 对应修改client = MongoClient(&#39;mongodb://username:pwd@ip:27017/dbname&#39;)db = client.dbname 服务器直接登陆 mongouse &amp;lt;dbname&amp;gt;db.auth(&#39;username&#39;, &#39;pwd&#39;) " }, { "title": "安装nginx", "url": "/posts/%E5%AE%89%E8%A3%85nginx/", "categories": "", "tags": "linux, nginx", "date": "2018-07-03 00:00:00 +0800", "snippet": "安装配置Nginx1.预备安装包apt-get install libpcre3 libpcre3-dev openssl libssl-dev libperl-dev2.清理残余的旧版本apt-get remove nginx nginx-common nginx-full3.安装nginx PGP签名文件wget http://nginx.org/keys/nginx_signing.keysudo apt-key add nginx_signing.key4.使用sudo修改source源codename参数根据os来选择，比如我的OS是Debian 8 jessie，codename参数即为jessievi /etc/apt/sources.list#在文件末追加以下,codename用os代号代替#Debian7.0 -&amp;gt; wheezy, 8.0 -&amp;gt; jessie, 9.0 -&amp;gt; stretchdeb http://nginx.org/packages/mainline/debian/ jessie nginxdeb-src http://nginx.org/packages/mainline/debian/ jessie nginx5.更新软件源并安装nginxapt-get updateapt-get install nginx6.查看nginx版本号nginx -v7.nginx启动service nginx startservice nginx restartservice nginx reloadservice nginx stop8.登陆网页检查登陆服务器IP或绑定的域名，看到熟悉的Nginx页面，安装成功。" }, { "title": "服务器部署selenium+chrome+chromedriver", "url": "/posts/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2selenium+chrome+chromedriver/", "categories": "", "tags": "linux, selenium", "date": "2018-06-05 00:00:00 +0800", "snippet": "服务器部署selenium+chrome+chromedriver系统版本 Debian8 (jessie)安装seleniumpip3 install selenium安装chrome在google-chrome官网(https://www.google.cn/chrome/)找到linux下载包（.deb）的链接。(可以先在自己电脑上下载，然后复制下载的链接)使用wget下载, dpkg安装chorme。wget urldpkg -i xxxxx.deb测试是否安装成功, 以及其版本：whereis google-chromegoogle-chrome -version #查询Chrome版本安装chromedriver在网上查询完对应chrome版本的chromedriver后在http://chromedriver.storage.googleapis.com/index.html下载到服务器。（目前最新chrome67对应chromedriver2.40）注意，直接下载(解压)到/usr/bin/目录下，否则报错‘’chromedriver’ executable needs to be in PATH’cd /usr/binwget URLunzip chromedriver_linux64.zip#没有unzip，用apt-get安装一下rm chromedriver_linux64.zip安装Xvfb上述包安装完成后还不能直接运行webdriver，因为没有一个“屏幕”作为输出。用Xvfb“虚构”一个屏幕。apt-get install xvfb#启动XvfbXvfb -ac :7 -screen 0 1280x1024x8export DISPLAY=:7每次重启服务器需要启动该服务，可将其写入启动脚本。基于带界面的py脚本增加指令from selenium.webdriver.chrome.options import Optionschrome_option = Options()chrome_option.add_argument(&#39;--headless&#39;)#无头模式，取代PhantomJSchrome_option.add_argument(&#39;--no-sandbox&#39;)#禁止沙盒模式chrome_option.add_argument(&#39;--disable-gpu&#39;)#禁止GPU加速其他报错 运行python脚本时关于selenium的报错 org.openqa.selenium.WebDriverException: unknown error: DevToolsActivePort file doesn’t exist意味着ChromeDriver无法启动/产生新的WebBrowser，即Chrome浏览器会话 。添加–disable-dev-shm-usage 参数暂时解决问题。 dpkg安装chrome时的报错 google-chrome-stable depends on libasound2 (&amp;gt;= 1.0.16); however: Package libasound2 is not installed.google-chrome-stable depends on libatk-bridge2.0-0 (&amp;gt;= 2.5.3); however: Package libatk-bridge2.0-0 is not installed.google-chrome-stable depends on libgtk-3-0 (&amp;gt;= 3.9.10); however: Package libgtk-3-0 is not installed.google-chrome-stable depends on libnspr4 (&amp;gt;= 2:4.9-2~); however: Package libnspr4 is not installed.google-chrome-stable depends on libnss3 (&amp;gt;= 2:3.22); however: Package libnss3 is not installed.google-chrome-stable depends on libx11-xcb1; however: Package libx11-xcb1 is not installed.google-chrome-stable depends on libxss1; however: Package libxss1 is not installed.google-chrome-stable dependdpkg: error processing package google-chrome-stable (–install):dependency problems - leaving unconfiguredProcessing triggers for man-db (2.7.0.2-5) …Processing triggers for mime-support (3.58) …Errors were encountered while processing:google-chrome-stableapt-get updateapt-get install libgconf2-4 libnss3-1d libxss1apt-get -f install#然后再运行dpkg那条指令" } ]
